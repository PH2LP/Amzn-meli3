#!/usr/bin/env python3
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 21_extract_keywords.py - EXTRAER KEYWORDS DE CATEGOR√çAS ML
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#
# ¬øQu√© hace?
#   Lee el archivo html_categories.txt con categor√≠as de MercadoLibre y genera keywords de Amazon.
#   Usa OpenAI API para analizar el texto y mantener contexto jer√°rquico.
#
#   IMPORTANTE: Mantiene el contexto de categor√≠a padre + subcategor√≠a
#   Ejemplo: Si ve "Beb√©s" ‚Üí "Juguetes", genera "baby toys" (NO solo "toys")
#
# Input:
#   - html_categories.txt
#
# Output:
#   - keywords_from_ml_categories.txt (keywords √∫nicos, ordenados alfab√©ticamente)
#
# Comando:
#   python3 21_extract_keywords.py
#
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
import os
import json
from openai import OpenAI
from pathlib import Path
from dotenv import load_dotenv

load_dotenv(override=True)

# Inicializar cliente OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def extract_categories_from_text(text_content):
    """Extrae categor√≠as del texto usando GPT-4"""
    print(f"üìù Procesando categor√≠as del archivo...")

    # Llamar a OpenAI API
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": f"""Eres un experto en e-commerce que convierte categor√≠as trending de MercadoLibre en keywords ESPEC√çFICAS y COMPLETAS para buscar productos en Amazon.

TEXTO A ANALIZAR:
{text_content}

CONTEXTO IMPORTANTE:
Estas son categor√≠as TRENDING de MercadoLibre. Tu trabajo es convertirlas en keywords ESPEC√çFICAS que se puedan usar para BUSCAR productos similares en Amazon.

REGLA CR√çTICA #1: NUNCA generes keywords gen√©ricas de 1 palabra
‚ùå MAL: "reptiles", "toys", "grooming", "food"
‚úÖ BIEN: "reptile terrariums", "reptile tanks", "cat toys", "dog grooming brushes"

REGLA CR√çTICA #2: SIEMPRE incluye el contexto completo
- Si dice "Other categories of Reptiles & Amphibians" y luego "Terrariums, Tanks & Boxes"
  ‚Üí Genera: "reptile terrariums", "reptile tanks", "reptile enclosures", "amphibian terrariums"

REGLA CR√çTICA #3: Piensa como un COMPRADOR de Amazon
- ¬øQu√© buscar√≠a alguien que quiere comprar esto?
- Usa t√©rminos completos y espec√≠ficos que se usan en Amazon
- Incluye variaciones comunes

EJEMPLOS REALES:

Input: "Other categories of Animals and Pets" ‚Üí "Pet Treats"
Output:
dog treats
cat treats
pet training treats
healthy pet treats
natural pet treats
dental dog treats

Input: "Other categories of Reptiles & Amphibians" ‚Üí "Terrariums, Tanks & Boxes"
Output:
reptile terrariums
reptile tanks
reptile enclosures
glass terrariums
amphibian tanks
snake terrariums
lizard tanks

Input: "Other categories of Cats" ‚Üí "Grooming & Care"
Output:
cat grooming brushes
cat nail clippers
cat grooming gloves
cat deshedding tools
cat grooming kit
cat dental care

Input: "Other categories of Horses" ‚Üí "Grooming & Care"
Output:
horse grooming brushes
horse curry combs
horse hoof picks
horse grooming kit
horse mane brush
horse tail brush

REGLAS DE EXPANSI√ìN:
1. Si ves "Toys" bajo "Cats", genera m√∫ltiples keywords: "cat toys", "interactive cat toys", "cat toy balls", "cat feather toys", etc.
2. Si ves "Food", expande: "dog food", "cat food", "dry dog food", "wet cat food", "organic pet food"
3. Piensa en VARIACIONES que un comprador real buscar√≠a
4. Incluye ADJETIVOS comunes: "natural", "organic", "premium", "training", "interactive", "automatic"
5. Incluye TIPOS espec√≠ficos cuando sea relevante

FILTROS ESTRICTOS:
- IGNORA "Other" como categor√≠a
- IGNORA porcentajes y n√∫meros
- IGNORA "Sales in this category..."
- NO generes keywords de 1 sola palabra
- NO generes keywords gen√©ricos sin contexto

FORMATO DE SALIDA:
- Un keyword por l√≠nea
- Sin numeraci√≥n, sin vi√±etas
- Solo el keyword en ingl√©s (min√∫sculas)
- M√≠nimo 2 palabras por keyword
- M√°ximo 4-5 palabras por keyword

IMPORTANTE: Genera entre 3-8 variaciones de keywords por cada categor√≠a, pensando en c√≥mo buscar√≠a un comprador REAL en Amazon."""
                }
            ],
            max_tokens=4000
        )

        # Extraer keywords de la respuesta
        keywords_text = response.choices[0].message.content

        # Limpiar keywords
        keywords = []
        for line in keywords_text.split('\n'):
            k = line.strip().lower()

            # Filtrar l√≠neas vac√≠as, comentarios, y respuestas de error de GPT
            if not k or k.startswith('#') or k.startswith('‚ùå') or k.startswith('‚úÖ'):
                continue

            # Filtrar respuestas de error comunes de GPT
            if "sorry" in k or "can't assist" in k or "cannot" in k:
                continue

            # Filtrar keywords que terminen en "other"
            if k.endswith(" other") or k == "other":
                continue

            # Remover texto innecesario
            k = k.replace(" in baby safety", "")
            k = k.replace(" in baby", "")

            # Agregar si no qued√≥ vac√≠o
            if k:
                keywords.append(k)

        # Extraer usage de tokens
        usage = response.usage
        input_tokens = usage.prompt_tokens
        output_tokens = usage.completion_tokens
        total_tokens = usage.total_tokens

        # Calcular costo (GPT-4o pricing: $2.50 per 1M input tokens, $10.00 per 1M output tokens)
        cost_input = (input_tokens / 1_000_000) * 2.50
        cost_output = (output_tokens / 1_000_000) * 10.00
        total_cost = cost_input + cost_output

        print(f"   ‚úÖ Extra√≠das {len(keywords)} keywords")
        print(f"   üìä Tokens: {total_tokens:,} (input: {input_tokens:,}, output: {output_tokens:,})")
        print(f"   üíµ Costo: ${total_cost:.4f}")

        return keywords, {"input_tokens": input_tokens, "output_tokens": output_tokens, "total_tokens": total_tokens, "cost": total_cost}

    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        return [], {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0, "cost": 0.0}

def main():
    print("=" * 80)
    print("EXTRACCI√ìN DE KEYWORDS DESDE html_categories.txt")
    print("=" * 80)
    print()

    # Leer archivo html_categories.txt
    input_file = Path(__file__).parent / "html_categories.txt"

    if not input_file.exists():
        print(f"‚ùå No se encontr√≥ el archivo: {input_file}")
        return

    with open(input_file, 'r', encoding='utf-8') as f:
        text_content = f.read()

    print(f"üìÇ Archivo encontrado: {input_file}")
    print(f"üìÑ Tama√±o: {len(text_content)} caracteres")
    print()

    # Procesar el texto
    all_keywords, stats = extract_categories_from_text(text_content)

    total_stats = {
        "input_tokens": stats["input_tokens"],
        "output_tokens": stats["output_tokens"],
        "total_tokens": stats["total_tokens"],
        "cost": stats["cost"]
    }

    # Cargar keywords existentes si el archivo ya existe
    output_file = Path(__file__).parent / "keywords_from_ml_categories.txt"
    existing_keywords = set()

    if output_file.exists():
        with open(output_file, 'r', encoding='utf-8') as f:
            existing_keywords = set(line.strip() for line in f if line.strip())
        print(f"üìù Cargadas {len(existing_keywords)} keywords existentes del archivo")

    # Combinar keywords nuevas con existentes
    all_keywords_set = set(all_keywords)
    all_keywords_set.update(existing_keywords)

    # Ordenar alfab√©ticamente
    sorted_keywords = sorted(all_keywords_set, key=str.lower)

    # Guardar en archivo (sobrescribir con lista completa)
    with open(output_file, 'w', encoding='utf-8') as f:
        for keyword in sorted_keywords:
            f.write(f"{keyword}\n")

    new_keywords_count = len(all_keywords_set) - len(existing_keywords)

    # Resumen
    print("=" * 80)
    print("‚úÖ PROCESAMIENTO COMPLETADO")
    print("=" * 80)
    print(f"Keywords extra√≠das:      {len(all_keywords)}")
    print(f"Keywords existentes:     {len(existing_keywords)}")
    print(f"Keywords nuevas:         {new_keywords_count}")
    print(f"Total keywords √∫nicas:   {len(sorted_keywords)}")
    print(f"Archivo guardado:        {output_file}")
    print()
    print("üìä CONSUMO TOTAL:")
    print(f"   Tokens totales:       {total_stats['total_tokens']:,}")
    print(f"   - Input tokens:       {total_stats['input_tokens']:,}")
    print(f"   - Output tokens:      {total_stats['output_tokens']:,}")
    print(f"   üíµ Costo total:       ${total_stats['cost']:.4f}")
    print()

    # Mostrar preview
    print("üìã Preview de keywords (primeras 20):")
    for i, keyword in enumerate(sorted_keywords[:20], 1):
        print(f"   {i:2d}. {keyword}")

    if len(sorted_keywords) > 20:
        print(f"   ... y {len(sorted_keywords) - 20} m√°s")
    print()

if __name__ == "__main__":
    main()
