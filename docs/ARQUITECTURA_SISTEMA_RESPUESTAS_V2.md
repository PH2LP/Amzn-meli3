# Arquitectura del Sistema de Respuestas Inteligente v2.0

## ğŸ¯ Objetivos del Sistema

1. **Coherencia 95%+**: Respuestas siempre coherentes con el producto
2. **InformaciÃ³n Completa**: Usar toda la info disponible del producto
3. **NotificaciÃ³n Inteligente**: Avisar cuando realmente no puede responder
4. **DetecciÃ³n de BÃºsquedas**: Identificar cuando piden productos especÃ­ficos
5. **Cero Mantenimiento**: No requiere agregar reglas nuevas

## ğŸ—ï¸ Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PREGUNTA ENTRANTE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 0: CLASIFICACIÃ“N INICIAL (GPT-4o-mini - rÃ¡pido/barato)â”‚
â”‚  Â¿Es bÃºsqueda de producto? Â¿Es pregunta tÃ©cnica crÃ­tica?    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                              â†“
   ES BÃšSQUEDA                    ES PREGUNTA NORMAL
        â”‚                              â†“
        â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚ FASE 1: EXTRACCIÃ“N DE INFORMACIÃ“N     â”‚
        â”‚              â”‚ - Preparar contexto del producto      â”‚
        â”‚              â”‚ - Identificar info relevante          â”‚
        â”‚              â”‚ - Calcular "confidence score"         â”‚
        â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                            â†“
        â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚ FASE 2: RAZONAMIENTO (GPT-4o/o1)     â”‚
        â”‚              â”‚ - Chain-of-Thought paso a paso        â”‚
        â”‚              â”‚ - Generar respuesta con razonamiento  â”‚
        â”‚              â”‚ - Auto-validaciÃ³n                     â”‚
        â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                            â†“
        â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚ FASE 3: VALIDACIÃ“N Y REFINAMIENTO    â”‚
        â”‚              â”‚ - Verificar coherencia                â”‚
        â”‚              â”‚ - Detectar contradicciones            â”‚
        â”‚              â”‚ - Self-consistency (crÃ­ticos)         â”‚
        â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                            â†“
        â”‚                     Â¿Confidence > 80%?
        â”‚                            â”‚
        â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â†“                       â†“
        â”‚              SÃ                       NO
        â”‚                â”‚                       â”‚
        â†“                â†“                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NOTIFICAR    â”‚  â”‚ RESPONDER    â”‚  â”‚ NOTIFICAR + NO       â”‚
â”‚ TELEGRAM     â”‚  â”‚ AL CLIENTE   â”‚  â”‚ RESPONDER            â”‚
â”‚ (bÃºsqueda)   â”‚  â”‚              â”‚  â”‚ (info insuficiente)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ FASE 1: ExtracciÃ³n de InformaciÃ³n del Producto

### Objetivo
Preparar un contexto rico, relevante y estructurado del producto.

### Fuentes de Datos (en orden de prioridad)

```python
Prioridad 1: mini_ml.json
  âœ… MÃ¡s compacto
  âœ… Ya procesado/limpio
  âœ… InformaciÃ³n especÃ­fica para ML

Prioridad 2: amazon_json (SP-API)
  âœ… InformaciÃ³n completa de Amazon
  âœ… Bullet points, specs, etc
  âš ï¸  MÃ¡s verboso

Prioridad 3: Descargar de Amazon
  âš ï¸  Solo si no existe
  âš ï¸  MÃ¡s lento
```

### Estructura del Contexto Preparado

```json
{
  "product_identity": {
    "title": "...",
    "brand": "...",
    "category": "...",
    "product_type": "smartwatch|doorbell|microphone|etc"
  },

  "specifications": {
    // Top 15 specs mÃ¡s relevantes
    "battery": "rechargeable lithium-ion",
    "connectivity": "Bluetooth 5.0, WiFi",
    "water_resistance": "IP67",
    ...
  },

  "features": [
    // Top 10 features mÃ¡s importantes
    "Heart rate monitoring",
    "Sleep tracking",
    ...
  ],

  "what_it_does": "...", // ExplicaciÃ³n simple del propÃ³sito
  "key_highlights": [...], // 3-5 puntos clave

  "dimensions_and_package": {
    "weight": "...",
    "dimensions": "...",
    "whats_included": [...]
  },

  "info_completeness": {
    "has_full_specs": true,
    "has_description": true,
    "has_features": true,
    "confidence_level": 0.95
  }
}
```

### Algoritmo de ExtracciÃ³n Inteligente

```python
def extract_smart_context(asin):
    """
    Extrae informaciÃ³n del producto de forma inteligente.
    """

    # 1. Cargar datos disponibles
    mini_ml = load_mini_ml(asin)
    amazon_json = load_amazon_json(asin)

    if not mini_ml and not amazon_json:
        # Ãšltimo recurso: descargar de Amazon
        amazon_json = download_from_amazon(asin)

    # 2. Usar GPT-4o-mini para ANALIZAR y EXTRAER
    # (No solo copiar, sino ENTENDER quÃ© es el producto)

    extraction_prompt = f"""
    Analiza este producto y extrae informaciÃ³n estructurada.

    Datos disponibles:
    {json.dumps(mini_ml or amazon_json, ensure_ascii=False)[:3000]}

    Tu trabajo:
    1. Identifica QUÃ‰ tipo de producto es (categorÃ­a real de uso)
    2. Extrae las 10 caracterÃ­sticas MÃS IMPORTANTES
    3. Extrae especificaciones tÃ©cnicas clave
    4. Resume en 1 lÃ­nea: "Para quÃ© sirve este producto"

    Responde en JSON:
    {{
      "product_type": "tipo especÃ­fico",
      "purpose": "para quÃ© sirve",
      "top_features": [...],
      "key_specs": {{...}},
      "completeness_score": 0.0-1.0
    }}
    """

    # Llamada a GPT-4o-mini (barato, ~$0.0001)
    extracted = call_gpt_mini(extraction_prompt)

    return extracted
```

### Ventajas de Este Enfoque

1. **Inteligente**: No solo copia datos, ENTIENDE el producto
2. **Relevante**: Filtra lo importante vs ruido
3. **Estructurado**: Formato consistente para razonamiento
4. **Con Confidence**: Sabe cuÃ¡nta info tiene

## ğŸ§  FASE 2: Sistema de Razonamiento Chain-of-Thought

### Modelo Recomendado: GPT-4o (o o1-preview para casos complejos)

**Por quÃ© GPT-4o:**
- Excelente razonamiento
- Buen balance costo/calidad
- ~$0.005 por 1K tokens (aceptable)

**CuÃ¡ndo usar o1-preview:**
- Preguntas muy tÃ©cnicas
- MÃºltiples sub-preguntas
- Cuando confidence < 60%
- ~$15 por 1M tokens (10x mÃ¡s caro pero mÃ¡s inteligente)

### Prompt Principal con Chain-of-Thought

```python
REASONING_PROMPT = """
Eres un asistente de ventas experto respondiendo preguntas de clientes.

INFORMACIÃ“N DEL PRODUCTO:
{product_context}

PREGUNTA DEL CLIENTE:
{question}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PIENSA PASO A PASO (usa <thinking> tags):

<thinking>
PASO 1 - ENTENDER EL PRODUCTO:
- Â¿QuÃ© tipo de producto es?
- Â¿Para quÃ© se usa normalmente?
- Â¿CuÃ¡les son sus caracterÃ­sticas principales?

PASO 2 - ENTENDER LA PREGUNTA:
- Â¿QuÃ© quiere saber realmente el cliente?
- Â¿Por quÃ© pregunta esto? (motivaciÃ³n)
- Â¿QuÃ© info necesita para decidir comprar?

PASO 3 - BUSCAR LA INFORMACIÃ“N:
- Â¿Tengo la informaciÃ³n que necesita?
- Â¿DÃ³nde estÃ¡ esa info en el contexto?
- Â¿Hay info adicional relevante?

PASO 4 - EVALUAR CONFIANZA:
- Â¿Puedo responder con certeza?
- Â¿O necesito que el vendedor verifique?
- Nivel de confianza: [0-100]%

PASO 5 - PLANEAR LA RESPUESTA:
- Â¿CÃ³mo presentar la info de forma Ãºtil?
- Â¿QuÃ© tono usar? (informativo/persuasivo/tÃ©cnico)
- Â¿Algo positivo para destacar?
</thinking>

AHORA GENERA LA RESPUESTA:

<response>
[Tu respuesta aquÃ­: 2-4 lÃ­neas, tono amigable y profesional]
</response>

<confidence>
[Tu nivel de confianza: 0-100]
</confidence>

<reasoning_summary>
[Breve resumen de por quÃ© respondiste asÃ­]
</reasoning_summary>

REGLAS CRÃTICAS:
- NUNCA inventes informaciÃ³n que no estÃ¡ en el contexto
- Si no tienes la info, di confidence=0 para que se notifique
- SÃ© positivo pero honesto
- No uses lenguaje robÃ³tico o templates
- Contextualiza segÃºn el tipo de producto
"""
```

### Procesamiento de la Respuesta

```python
def generate_smart_answer(question, product_context):
    """
    Genera respuesta con razonamiento estructurado.
    """

    # 1. Preparar prompt con contexto
    prompt = REASONING_PROMPT.format(
        product_context=json.dumps(product_context, ensure_ascii=False, indent=2),
        question=question
    )

    # 2. Llamar a GPT-4o con razonamiento
    response = openai.chat.completions.create(
        model="gpt-4o",  # o "o1-preview" para casos complejos
        messages=[
            {"role": "user", "content": prompt}
        ],
        max_tokens=800,
        temperature=0.3  # MÃ¡s determinÃ­stico
    )

    full_output = response.choices[0].message.content

    # 3. Parsear respuesta estructurada
    parsed = parse_structured_response(full_output)

    return {
        "answer": parsed["response"],
        "confidence": parsed["confidence"],
        "reasoning": parsed["reasoning_summary"],
        "thinking": parsed["thinking"]  # Para debugging
    }
```

## âœ… FASE 3: ValidaciÃ³n y Control de Calidad

### Sistema de Confidence Scoring

```python
def calculate_final_confidence(result, product_context):
    """
    Calcula confianza final considerando mÃºltiples factores.
    """

    confidence_factors = []

    # Factor 1: Confidence del modelo
    model_confidence = result["confidence"]
    confidence_factors.append(("model", model_confidence, 0.5))

    # Factor 2: Completitud de la informaciÃ³n del producto
    info_completeness = product_context["info_completeness"]["confidence_level"]
    confidence_factors.append(("info", info_completeness * 100, 0.2))

    # Factor 3: Longitud de respuesta (muy corta = sospechoso)
    answer_length = len(result["answer"].split())
    length_score = min(100, (answer_length / 20) * 100)  # 20 palabras = 100%
    confidence_factors.append(("length", length_score, 0.1))

    # Factor 4: No hay palabras sospechosas
    suspicious_words = ["no tengo", "consulta", "verificar", "no especifica"]
    has_suspicious = any(word in result["answer"].lower() for word in suspicious_words)
    suspicious_score = 0 if has_suspicious else 100
    confidence_factors.append(("no_suspicious", suspicious_score, 0.2))

    # Calcular weighted average
    final_confidence = sum(score * weight for _, score, weight in confidence_factors)

    return {
        "final_confidence": final_confidence,
        "breakdown": confidence_factors
    }
```

### Self-Consistency (para preguntas crÃ­ticas)

```python
def apply_self_consistency(question, product_context, n=3):
    """
    Genera N respuestas y selecciona la mÃ¡s consistente.
    Usar solo para preguntas crÃ­ticas (voltaje, compatibilidad, etc).
    """

    responses = []

    # Generar N respuestas con temperatura ligeramente diferente
    for i in range(n):
        response = generate_smart_answer(
            question,
            product_context,
            temperature=0.2 + (i * 0.1)  # 0.2, 0.3, 0.4
        )
        responses.append(response)

    # Usar GPT-4o para seleccionar la mÃ¡s consistente y precisa
    consistency_prompt = f"""
    Analiza estas {n} respuestas a la misma pregunta:

    Pregunta: {question}

    Respuestas:
    {json.dumps([r["answer"] for r in responses], indent=2)}

    Â¿CuÃ¡l es la MÃS PRECISA y CONSISTENTE?
    Responde con el nÃºmero (0, 1, 2) y por quÃ©.
    """

    selection = call_gpt_mini(consistency_prompt)
    best_index = extract_number(selection)

    return responses[best_index]
```

### DetecciÃ³n de Contradicciones

```python
def check_contradictions(answer, product_context):
    """
    Verifica que la respuesta no se contradiga.
    """

    validation_prompt = f"""
    Producto: {product_context["product_identity"]["title"]}
    Respuesta generada: "{answer}"

    Verifica:
    1. Â¿Hay contradicciones internas? (ej: "SÃ­... pero no")
    2. Â¿Es coherente con el tipo de producto?
    3. Â¿El tono es apropiado para ventas?

    Responde JSON:
    {{
      "has_contradictions": true/false,
      "issues": ["lista de problemas"],
      "is_coherent": true/false,
      "score": 0-100
    }}
    """

    validation = call_gpt_mini(validation_prompt)
    return validation
```

## ğŸ” FASE 0: ClasificaciÃ³n y DetecciÃ³n

### Detectar BÃºsquedas de Productos

```python
def detect_product_search(question, item_context=None):
    """
    Detecta si el cliente estÃ¡ buscando un producto especÃ­fico.
    Mejorado con razonamiento.
    """

    detection_prompt = f"""
    Analiza esta pregunta y determina si el cliente estÃ¡ BUSCANDO un producto especÃ­fico
    que NO es el producto actual en la publicaciÃ³n.

    Pregunta: "{question}"
    Producto actual: {item_context.get("title") if item_context else "N/A"}

    Ejemplos de BÃšSQUEDA:
    - "TenÃ©s el modelo XYZ?"
    - "VendÃ©s auriculares Sony?"
    - "CuÃ¡nto sale el iPhone 15?"

    Ejemplos de NO BÃšSQUEDA:
    - "De quÃ© color es?"
    - "Funciona con pilas?"
    - "CuÃ¡nto cuesta?" (pregunta sobre el producto actual)

    Responde JSON:
    {{
      "is_product_search": true/false,
      "product_mentioned": "nombre del producto buscado o null",
      "confidence": 0-100,
      "reasoning": "breve explicaciÃ³n"
    }}
    """

    result = call_gpt_mini(detection_prompt)
    return result
```

### Detectar Preguntas TÃ©cnicas CrÃ­ticas

```python
CRITICAL_TOPICS = {
    "electrical_safety": [
        "voltaje", "voltage", "110v", "220v", "transformador",
        "transformer", "se quema", "burn", "electricidad"
    ],
    "health_safety": [
        "alergias", "allergic", "tÃ³xico", "toxic", "seguro para niÃ±os",
        "safe for children", "fda approved"
    ],
    "legal_compliance": [
        "certificaciÃ³n", "certification", "garantÃ­a", "warranty",
        "anatel", "homologado", "approved"
    ]
}

def is_critical_question(question):
    """
    Detecta preguntas que requieren informaciÃ³n precisa del fabricante.
    """

    question_lower = question.lower()

    for category, keywords in CRITICAL_TOPICS.items():
        for keyword in keywords:
            if keyword in question_lower:
                return {
                    "is_critical": True,
                    "category": category,
                    "reason": f"Pregunta sobre {category}"
                }

    return {"is_critical": False}
```

## ğŸ“¢ Sistema de Notificaciones Inteligente

### CuÃ¡ndo Notificar

```python
NOTIFICATION_RULES = {
    "product_search": {
        "notify": True,
        "respond": False,
        "reason": "Cliente busca producto especÃ­fico"
    },
    "critical_question": {
        "notify": True,
        "respond": False,
        "reason": "Pregunta tÃ©cnica crÃ­tica (seguridad/legal)"
    },
    "low_confidence": {
        "notify": True,
        "respond": False,
        "threshold": 70,
        "reason": "InformaciÃ³n insuficiente para responder con seguridad"
    },
    "medium_confidence": {
        "notify": True,
        "respond": True,
        "threshold": 85,
        "reason": "Respuesta generada pero requiere revisiÃ³n"
    },
    "high_confidence": {
        "notify": False,
        "respond": True,
        "threshold": 100,
        "reason": "Respuesta confiable"
    }
}
```

### Mejorar Notificaciones Telegram

```python
def send_smart_notification(
    question_id,
    question_text,
    notification_type,
    context
):
    """
    NotificaciÃ³n inteligente con contexto completo.
    """

    if notification_type == "product_search":
        message = f"""
ğŸ” <b>BÃšSQUEDA DE PRODUCTO</b>

ğŸ‘¤ Cliente: {context['customer']}
ğŸ’¬ Pregunta: "{question_text}"

ğŸ¯ Producto buscado: {context['product_searched']}
ğŸ“Š Confidence: {context['confidence']}%

ğŸ“± <a href="{context['question_url']}">Responder manualmente</a>
        """

    elif notification_type == "low_confidence":
        message = f"""
âš ï¸ <b>PREGUNTA COMPLEJA - Respuesta Manual Requerida</b>

ğŸ‘¤ Cliente: {context['customer']}
ğŸ’¬ Pregunta: "{question_text}"

â“ RazÃ³n: {context['reason']}
ğŸ“Š Confidence: {context['confidence']}%

ğŸ’¡ Razonamiento del sistema:
{context['reasoning'][:200]}...

ğŸ”— ASIN: {context['asin']}
ğŸ“± <a href="{context['question_url']}">Responder manualmente</a>
        """

    elif notification_type == "medium_confidence":
        message = f"""
âœ… <b>RESPUESTA GENERADA - RevisiÃ³n Recomendada</b>

ğŸ‘¤ Cliente: {context['customer']}
ğŸ’¬ Pregunta: "{question_text}"

ğŸ¤– Respuesta generada:
"{context['generated_answer']}"

ğŸ“Š Confidence: {context['confidence']}%
âš ï¸ Revisa antes de 24h para ajustar si es necesario

ğŸ“± <a href="{context['question_url']}">Ver en ML</a>
        """

    send_telegram_message(message)
```

## ğŸ¯ Flujo Completo - Ejemplo

```python
def answer_question_v2(question, asin, question_id, customer, site_id):
    """
    Sistema completo de respuestas v2.0
    """

    # PASO 0: ClasificaciÃ³n inicial
    search_detection = detect_product_search(question)

    if search_detection["is_product_search"] and search_detection["confidence"] > 80:
        send_smart_notification(
            question_id, question, "product_search",
            context={"product_searched": search_detection["product_mentioned"], ...}
        )
        return {"action": "no_answer", "reason": "product_search"}

    critical = is_critical_question(question)
    if critical["is_critical"]:
        send_smart_notification(
            question_id, question, "critical_question",
            context={"category": critical["category"], ...}
        )
        return {"action": "no_answer", "reason": "critical"}

    # PASO 1: ExtracciÃ³n de informaciÃ³n
    product_context = extract_smart_context(asin)

    # PASO 2: Generar respuesta con razonamiento
    result = generate_smart_answer(question, product_context)

    # PASO 3: Calcular confidence final
    confidence_analysis = calculate_final_confidence(result, product_context)
    final_confidence = confidence_analysis["final_confidence"]

    # PASO 4: Validar (solo si confidence > 50%)
    if final_confidence > 50:
        validation = check_contradictions(result["answer"], product_context)
        if not validation["is_coherent"]:
            final_confidence = final_confidence * 0.7  # Penalizar

    # PASO 5: Self-consistency para preguntas importantes
    if critical["category"] in ["electrical_safety"] and final_confidence < 90:
        result = apply_self_consistency(question, product_context, n=3)
        final_confidence = min(95, final_confidence + 10)  # Boost por self-consistency

    # PASO 6: Decidir acciÃ³n
    if final_confidence < 70:
        # NO responder, notificar
        send_smart_notification(
            question_id, question, "low_confidence",
            context={
                "confidence": final_confidence,
                "reasoning": result["reasoning"],
                ...
            }
        )
        return {"action": "no_answer", "reason": "low_confidence"}

    elif final_confidence < 85:
        # Responder PERO notificar para revisiÃ³n
        send_smart_notification(
            question_id, question, "medium_confidence",
            context={
                "generated_answer": result["answer"],
                "confidence": final_confidence,
                ...
            }
        )
        post_answer_to_ml(question_id, result["answer"])
        return {"action": "answered", "confidence": "medium"}

    else:
        # Responder con confianza, NO notificar
        post_answer_to_ml(question_id, result["answer"])
        return {"action": "answered", "confidence": "high"}
```

## ğŸ’° AnÃ¡lisis de Costos

### EstimaciÃ³n por Pregunta

```
FASE 0: ClasificaciÃ³n (GPT-4o-mini)
  - Input: ~200 tokens
  - Output: ~100 tokens
  - Costo: ~$0.00002

FASE 1: ExtracciÃ³n (GPT-4o-mini)
  - Input: ~1500 tokens
  - Output: ~300 tokens
  - Costo: ~$0.00015

FASE 2: Razonamiento (GPT-4o)
  - Input: ~800 tokens
  - Output: ~400 tokens
  - Costo: ~$0.006

FASE 3: ValidaciÃ³n (GPT-4o-mini)
  - Input: ~300 tokens
  - Output: ~100 tokens
  - Costo: ~$0.00003

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL POR PREGUNTA: ~$0.0064 USD
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Con 100 preguntas/dÃ­a:
  - Costo diario: $0.64
  - Costo mensual: ~$19

Casos con o1-preview (5% de casos):
  - Costo por pregunta: ~$0.03
  - Impact mensual: +$5

COSTO TOTAL MENSUAL: ~$24 USD
```

### ROI
- Costo actual: ~$5/mes (pero respuestas malas)
- Costo nuevo: ~$24/mes (respuestas excelentes)
- **InversiÃ³n adicional: $19/mes**
- **Beneficio: Ventas no perdidas por respuestas malas = invaluable**

## ğŸ“Š MÃ©tricas de Ã‰xito

### Tracking AutomÃ¡tico

```python
METRICS = {
    "total_questions": 0,
    "answered_automatically": 0,
    "notified_product_search": 0,
    "notified_critical": 0,
    "notified_low_confidence": 0,
    "average_confidence": 0.0,
    "contradictions_detected": 0,
    "self_consistency_applied": 0
}
```

### Objetivos

```
Mes 1 (implementaciÃ³n):
  - Answered automatically: >70%
  - Average confidence: >80%
  - Contradictions: <2%

Mes 2 (optimizaciÃ³n):
  - Answered automatically: >85%
  - Average confidence: >85%
  - Contradictions: <1%

Mes 3 (madurez):
  - Answered automatically: >90%
  - Average confidence: >90%
  - Contradictions: <0.5%
```

## ğŸš€ Plan de ImplementaciÃ³n

### Semana 1: Core
- [ ] Sistema de extracciÃ³n de informaciÃ³n
- [ ] Prompt Chain-of-Thought bÃ¡sico
- [ ] Confidence scoring
- [ ] Tests unitarios

### Semana 2: ValidaciÃ³n
- [ ] DetecciÃ³n de contradicciones
- [ ] Self-consistency
- [ ] Mejora de clasificaciÃ³n inicial
- [ ] Tests de integraciÃ³n

### Semana 3: Notificaciones
- [ ] Sistema de notificaciones mejorado
- [ ] Dashboard de mÃ©tricas
- [ ] Logging detallado
- [ ] DocumentaciÃ³n

### Semana 4: ProducciÃ³n
- [ ] Deploy gradual (10% trÃ¡fico)
- [ ] Monitoreo activo
- [ ] Ajustes basados en datos reales
- [ ] Rollout completo

---

**PrÃ³ximo paso:** Implementar el cÃ³digo completo.
