#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
search_12_per_keyword.py
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
B√öSQUEDA INTELIGENTE: TOP N ASINs POR KEYWORD (IA OPTIMIZADA AL FINAL)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Sistema de b√∫squeda con validaci√≥n IA SOLO al final, evaluando 1x1 hasta obtener
los N ASINs solicitados (98%+ ahorro tokens).

CARACTER√çSTICAS:
- ‚úÖ Filtra 1000 ASINs sin IA (solo blacklist b√°sica)
- ‚úÖ Ordena por BSR (mejor ranking primero)
- ‚úÖ Validaci√≥n IA 1x1 hasta obtener N aprobados (early stopping)
- ‚úÖ Triple filtrado: B√°sico + Prime + BSR + IA final
- ‚úÖ 98%+ reducci√≥n tokens IA vs sistema anterior

FLUJO POR KEYWORD (OPTIMIZADO):
1. Buscar 100 p√°ginas en Amazon (~1000 ASINs)
2. Filtrar por blacklist b√°sica (SIN IA - batch API)
3. Filtrar por Prime + Fast Fulfillment
4. Ordenar TODOS los ASINs por BSR (mejor‚Üípeor)
5. VALIDACI√ìN FINAL IA (1x1, early stopping):
   - Eval√∫a candidatos en orden BSR (mejor primero)
   - BrandIntelligenceFilter: detecta marcas prohibidas + categor√≠as con IA
   - AIProductSafetyFilter: an√°lisis profundo GPT-4o-mini
   - Detiene cuando obtiene N aprobados (ej: 8)
6. Guardar en asins.txt

INNOVACIONES:
- üí∞ 98%+ reducci√≥n tokens: IA solo en ~8-15 ASINs (antes: ~400)
- üìä Prioriza productos con mejor BSR (m√°s vendidos en Amazon)
- ‚ö° Early stopping agresivo: detiene evaluaci√≥n cuando tiene suficientes
- üéØ Validaci√≥n IA exhaustiva solo donde importa

COMPARATIVA:
- Sistema anterior: ~400 ASINs evaluados con IA = ~320k tokens/keyword
- Sistema nuevo: ~8-15 ASINs evaluados con IA = ~6-12k tokens/keyword
- Ahorro: ~98% reducci√≥n en costos IA

EJEMPLO REAL:
- Si encuentra 8 aprobados en los primeros 10 ASINs ‚Üí Solo eval√∫a 10
- Si hay m√°s rechazos ‚Üí Eval√∫a hasta ~15-20 ASINs
- Nunca m√°s de 30-40 ASINs (si hay muchos rechazos)

USO:
    python scripts/autonomous/search_12_per_keyword.py
    python scripts/autonomous/search_12_per_keyword.py --keywords-file ~/Desktop/mis-keywords.txt
    python scripts/autonomous/search_12_per_keyword.py --asins-per-keyword 12
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""

import os
import sys
import json
import time
from pathlib import Path
from datetime import datetime
from typing import List, Tuple

# A√±adir project root al path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / 'src'))
sys.path.insert(0, str(project_root / 'scripts'))

from autonomous.brand_filter import ProductFilter
from tools.search_asins_by_keyword import search_products_by_keyword
from integrations.amazon_pricing import get_prime_offers_batch_optimized
from integrations.amazon_api import get_products_batch, get_product_bsr_only

# Import NEW AI Safety Filter (reemplaza ProductFilter para mayor protecci√≥n)
from src.filters.ai_product_safety_filter import AIProductSafetyFilter
from src.filters.brand_intelligence_filter import BrandIntelligenceFilter


class SimpleKeywordSearch:
    """
    B√∫squeda inteligente: Top 8 ASINs por BSR para cada keyword
    Con evaluaci√≥n IA de marcas y filtrado de productos prohibidos
    """

    def __init__(self, keywords_file: str = None, output_file: str = None, asins_per_keyword: int = 8, process_id: int = 0):
        """
        Inicializa el buscador

        Args:
            keywords_file: Path al archivo de keywords (default: ~/Desktop/asins-1000.txt)
            output_file: Path al archivo de salida (default: asins.txt)
            asins_per_keyword: N√∫mero de ASINs por keyword (default: 8)
            process_id: ID del proceso (0-3) para evitar colisiones en parallel search
        """
        # Archivo de keywords
        if keywords_file:
            self.keywords_file = Path(keywords_file).expanduser()
        else:
            self.keywords_file = Path("~/Desktop/asins-1000.txt").expanduser()

        # Archivos de salida
        if output_file:
            self.output_file = Path(output_file)
        else:
            self.output_file = project_root / "asins.txt"

        self.log_file = project_root / "storage" / "autonomous_logs" / "search_12_per_keyword.log"
        self.log_file.parent.mkdir(parents=True, exist_ok=True)

        # Configuraci√≥n
        self.asins_per_keyword = asins_per_keyword
        self.process_id = process_id  # Para delays escalonados en parallel search

        # Componentes
        # NUEVO SISTEMA SIMPLIFICADO (Nov 2024):
        # - Whitelist ‚Üí Blacklist (4,771) ‚Üí Wikidata ‚Üí IA (solo categor√≠as) ‚Üí Default APPROVE
        self.brand_filter = BrandIntelligenceFilter()

        # Mantener filters viejos como fallback (por si acaso)
        self.safety_filter = AIProductSafetyFilter()
        self.product_filter = ProductFilter()

        # Configuraci√≥n fija
        # NUEVO: Tomar TODOS los ASINs encontrados (no limitar a 100)
        # Evaluamos uno por uno de mejor a peor BSR hasta encontrar los 9
        # self.asins_per_keyword ya fue configurado en __init__ (l√≠nea 100)
        self.search_pages = 100  # 100 p√°ginas = ~1000 ASINs

        # M√©tricas
        self.total_keywords_processed = 0
        self.total_asins_found = 0
        self.start_time = datetime.now()

        self.log("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        self.log("üîç B√öSQUEDA OPTIMIZADA: IA SOLO AL FINAL (98%+ AHORRO TOKENS)")
        self.log("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
        self.log(f"üìÑ Keywords file: {self.keywords_file}")
        self.log(f"üíæ Output file: {self.output_file}")
        self.log(f"üìä Target: Top {self.asins_per_keyword} ASINs por keyword")
        self.log(f"üìÑ P√°ginas b√∫squeda: {self.search_pages} p√°ginas (~{self.search_pages * 10} ASINs)")
        self.log(f"")
        self.log(f"üéØ PIPELINE OPTIMIZADO (5 FASES):")
        self.log(f"   1Ô∏è‚É£  B√∫squeda Amazon: ~1000 ASINs por keyword")
        self.log(f"   2Ô∏è‚É£  Filtro b√°sico: Blacklist sin IA (batch API)")
        self.log(f"   3Ô∏è‚É£  Filtro Prime: Solo Prime + Fast Fulfillment")
        self.log(f"   4Ô∏è‚É£  Ranking BSR: Ordenar por ventas (mejor‚Üípeor)")
        self.log(f"   5Ô∏è‚É£  VALIDACI√ìN IA 1x1: Evaluar hasta obtener {self.asins_per_keyword} aprobados ‚ú®")
        self.log(f"")
        self.log(f"üí∞ OPTIMIZACI√ìN IA (EARLY STOPPING):")
        self.log(f"   ‚Ä¢ Sistema anterior: ~400 ASINs con IA = ~320k tokens")
        self.log(f"   ‚Ä¢ Sistema nuevo: ~8-15 ASINs con IA = ~6-12k tokens")
        self.log(f"   ‚Ä¢ Ahorro: 98%+ reducci√≥n tokens IA üéâ")
        self.log(f"")
        self.log(f"ü§ñ VALIDACI√ìN IA FINAL (early stopping agresivo):")
        self.log(f"   ‚Ä¢ Eval√∫a ASINs 1x1 en orden BSR (mejor primero)")
        self.log(f"   ‚Ä¢ BrandIntelligenceFilter: Marcas prohibidas + categor√≠as")
        self.log(f"   ‚Ä¢ AIProductSafetyFilter: An√°lisis profundo GPT-4o-mini")
        self.log(f"   ‚Ä¢ Detiene INMEDIATAMENTE al obtener {self.asins_per_keyword} aprobados")
        self.log("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")

    def log(self, message: str, level: str = "INFO", keyword: str = None):
        """Escribe log en archivo y consola"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        if keyword:
            log_line = f"[{timestamp}] [{level}] [{keyword}] {message}"
        else:
            log_line = f"[{timestamp}] [{level}] {message}"

        print(log_line)

        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_line + "\n")

    def load_keywords(self) -> List[str]:
        """
        Carga keywords desde el archivo (soporta TXT y JSON)

        Returns:
            list: Lista de keywords
        """
        if not self.keywords_file.exists():
            self.log(f"‚ùå Archivo no encontrado: {self.keywords_file}", "ERROR")
            return []

        # Detectar si es JSON por la extensi√≥n
        if self.keywords_file.suffix.lower() == '.json':
            import json
            try:
                with open(self.keywords_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # Extraer keywords del formato JSON
                # Formato: {"keywords": [{"keyword": "...", ...}, ...]}
                keywords_list = data.get("keywords", [])

                # Si es una lista de dicts, extraer el campo "keyword"
                if keywords_list and isinstance(keywords_list[0], dict):
                    keywords = [kw.get("keyword", "") for kw in keywords_list if kw.get("keyword")]
                # Si es una lista de strings directamente
                elif keywords_list and isinstance(keywords_list[0], str):
                    keywords = keywords_list
                else:
                    self.log(f"‚ö†Ô∏è  Formato JSON no reconocido en {self.keywords_file}", "WARNING")
                    keywords = []

                self.log(f"üìã Cargadas {len(keywords)} keywords desde JSON: {self.keywords_file}")
                return keywords

            except json.JSONDecodeError as e:
                self.log(f"‚ùå Error parseando JSON: {e}", "ERROR")
                return []

        # Archivo TXT: leer l√≠nea por l√≠nea
        else:
            with open(self.keywords_file, 'r', encoding='utf-8') as f:
                keywords = [
                    line.strip()
                    for line in f
                    if line.strip() and not line.startswith("#")
                ]

            self.log(f"üìã Cargadas {len(keywords)} keywords desde TXT: {self.keywords_file}")
            return keywords

    def filter_asins_by_brand_batch(self, asins: List[str], keyword: str) -> Tuple[List[str], List[dict]]:
        """
        Filtra ASINs por marcas + categor√≠as prohibidas usando BATCH API

        Args:
            asins: Lista de ASINs a filtrar
            keyword: Keyword actual (para logs)

        Returns:
            Tuple[list, list]: (asins_permitidos, asins_rechazados)
        """
        # Delay escalonado por proceso para evitar colisiones en batch API
        if self.process_id > 0:
            process_delay = self.process_id * 15  # 0s, 15s, 30s (3 procesos)
            time.sleep(process_delay)

        allowed = []
        rejected = []

        # Procesar en batches de 20 ASINs
        batch_size = 20
        total_batches = (len(asins) + batch_size - 1) // batch_size

        for batch_num, i in enumerate(range(0, len(asins), batch_size), 1):
            batch = asins[i:i+batch_size]

            self.log(f"   Batch {batch_num}/{total_batches}: Verificando {len(batch)} ASINs...", keyword=keyword)

            # Delay aleatorio peque√±o para desincronizar procesos
            if self.process_id > 0:
                import random
                stagger_delay = random.randint(5, 15)  # 5-15s aleatorio
                time.sleep(stagger_delay)

            # Retry logic con backoff exponencial
            max_retries = 5
            for attempt in range(max_retries):
                try:
                    # Obtener datos de 20 ASINs en 1 sola llamada
                    products_data = get_products_batch(batch, include_data="summaries")

                    # Filtrar cada producto
                    for asin in batch:
                        product_data = products_data.get(asin)

                        if not product_data:
                            rejected.append({"asin": asin, "reason": "No se pudo obtener info"})
                            continue

                        # Verificaci√≥n con AIProductSafetyFilter (usa WHITELIST + keywords, sin IA)
                        # Nota: El filtro AI profundo se ejecuta UNO POR UNO en evaluaci√≥n final
                        is_safe, reason_unsafe, confidence = self.safety_filter.is_safe_to_publish(
                            asin, product_data, use_ai=False  # Solo keywords + whitelist, sin IA
                        )

                        if not is_safe:
                            # Producto prohibido seg√∫n filtro b√°sico
                            rejected.append({"asin": asin, "reason": f"Keywords:{reason_unsafe}"})
                            continue

                        # Producto APROBADO
                        allowed.append(asin)

                    break  # Batch exitoso, salir del retry loop

                except Exception as e:
                    # Si es rate limit, reintentar despu√©s de esperar
                    if "429" in str(e) and attempt < max_retries - 1:
                        # Backoff exponencial suave + jitter POR PROCESO (rangos diferentes)
                        import random
                        base_wait = int(10 * (1.5 ** attempt))  # 10s, 15s, 22s, 33s, 50s

                        # Jitter basado en process_id para GARANTIZAR que NO se pisen
                        jitter_min = self.process_id * 20      # P0:0, P1:20, P2:40
                        jitter_max = (self.process_id + 1) * 20  # P0:20, P1:40, P2:60
                        jitter = random.randint(jitter_min, jitter_max)

                        wait_time = base_wait + jitter

                        self.log(f"   ‚è±Ô∏è Rate limit (429) en batch {batch_num}, esperando {wait_time}s antes de reintentar (intento {attempt + 1}/{max_retries})...", "WARNING", keyword=keyword)
                        time.sleep(wait_time)
                        continue
                    else:
                        # Error final despu√©s de max retries: SALTAR batch y continuar
                        if "429" in str(e):
                            self.log(f"   ‚ö†Ô∏è Rate limit persistente despu√©s de {max_retries} intentos en batch {batch_num} - SALTANDO batch", "WARNING", keyword=keyword)
                        else:
                            self.log(f"   ‚ö†Ô∏è Error en batch {batch_num}: {e} - SALTANDO batch", "WARNING", keyword=keyword)

                        # Rechazar todo el batch en caso de error pero CONTINUAR
                        for asin in batch:
                            rejected.append({"asin": asin, "reason": f"Batch fallido: {str(e)[:50]}"})
                        break  # Salir del retry loop y CONTINUAR con siguiente batch

            # Delay entre batches (aumentado para procesos paralelos)
            if i + batch_size < len(asins):
                time.sleep(5)

        return allowed, rejected

    def filter_prime_asins(self, asins: List[str], keyword: str) -> List[str]:
        """
        Filtra ASINs por Prime + Fast Fulfillment

        Args:
            asins: Lista de ASINs a filtrar
            keyword: Keyword actual (para logs)

        Returns:
            list: ASINs con Prime v√°lido
        """
        if not asins:
            return []

        self.log(f"‚≠ê Filtrando {len(asins)} ASINs por Prime + Fast Fulfillment...", keyword=keyword)

        # Delay aleatorio peque√±o para desincronizar procesos
        if self.process_id > 0:
            import random
            process_delay = random.randint(5, 20)  # 5-20s aleatorio
            time.sleep(process_delay)

        # Obtener ofertas Prime en batch
        prime_offers = get_prime_offers_batch_optimized(asins, batch_size=20, show_progress=True)

        # Filtrar solo ASINs con oferta Prime v√°lida
        prime_asins = [
            asin for asin, offer in prime_offers.items()
            if offer is not None and offer.get("is_prime") and offer.get("price", 0) > 0
        ]

        rejected = len(asins) - len(prime_asins)

        self.log(f"‚úÖ Prime: {len(prime_asins)}/{len(asins)} ASINs", keyword=keyword)
        self.log(f"   ‚ùå Rechazados: {rejected} ASINs", keyword=keyword)

        return prime_asins

    def rank_asins_by_bsr(self, asins: List[str], keyword: str) -> List[str]:
        """
        Ordena ASINs por BSR y retorna los top 12 m√°s vendidos

        Args:
            asins: Lista de ASINs a ordenar
            keyword: Keyword actual (para logs)

        Returns:
            list: Top 12 ASINs ordenados por BSR (menor = m√°s vendido)
        """
        self.log(f"üìä Obteniendo BSR de {len(asins)} ASINs para ordenar por ventas...", keyword=keyword)
        self.log(f"   Esto tomar√° ~{len(asins) * 2 // 60} minutos (2s por ASIN)", keyword=keyword)

        # Delay escalonado por proceso para evitar colisiones en BSR requests
        if self.process_id > 0:
            process_delay = self.process_id * 15  # 0s, 15s, 30s (3 procesos)
            time.sleep(process_delay)

        asins_with_bsr = []

        # Procesar cada ASIN
        for i, asin in enumerate(asins, 1):
            try:
                self.log(f"   [{i}/{len(asins)}] Obteniendo BSR de {asin}...", keyword=keyword)

                bsr = get_product_bsr_only(asin)

                if bsr:
                    asins_with_bsr.append({"asin": asin, "bsr": bsr})
                    self.log(f"      ‚úÖ BSR: {bsr:,}", keyword=keyword)
                else:
                    self.log(f"      ‚ö†Ô∏è Sin BSR", keyword=keyword)

                # Delay entre requests (aumentado para procesos paralelos)
                time.sleep(4)

            except Exception as e:
                self.log(f"   ‚ö†Ô∏è Error obteniendo BSR de {asin}: {e}", "WARNING", keyword=keyword)

        if not asins_with_bsr:
            self.log(f"‚ùå No se pudo obtener BSR de ning√∫n ASIN", "ERROR", keyword=keyword)
            return []

        # Ordenar por BSR (menor = m√°s vendido = primero)
        asins_with_bsr.sort(key=lambda x: x["bsr"])

        # NUEVO: Tomar TODOS los ASINs (no limitar a 100)
        # La evaluaci√≥n uno por uno se detendr√° cuando encuentre los 9 necesarios
        all_asins = [item["asin"] for item in asins_with_bsr]

        self.log(f"‚úÖ Ranking completado: {len(asins_with_bsr)} ASINs ordenados por BSR (mejor‚Üípeor)", keyword=keyword)

        if all_asins:
            self.log(f"   üèÜ Mejor BSR: {asins_with_bsr[0]['bsr']:,} (ASIN: {asins_with_bsr[0]['asin']})", keyword=keyword)
            if len(asins_with_bsr) > 1:
                last_idx = len(asins_with_bsr) - 1
                self.log(f"   üìâ Peor BSR: {asins_with_bsr[last_idx]['bsr']:,} (ASIN: {asins_with_bsr[last_idx]['asin']})", keyword=keyword)
            self.log(f"   üéØ Evaluaremos de mejor a peor hasta encontrar {self.asins_per_keyword} aprobados", keyword=keyword)

        return all_asins

    def _check_relevance_with_ai(self, title: str, keyword: str, brand: str = "") -> bool:
        """
        Verifica con IA si el producto es RELEVANTE a la keyword buscada

        Args:
            title: T√≠tulo del producto
            keyword: Keyword que se busc√≥
            brand: Marca del producto (opcional)

        Returns:
            bool: True si es relevante, False si no
        """
        try:
            import openai

            prompt = f"""Analiza si este producto es RELEVANTE a la b√∫squeda del usuario.

KEYWORD BUSCADA: "{keyword}"

PRODUCTO:
- T√≠tulo: "{title}"
- Marca: "{brand if brand else 'Sin marca'}"

EJEMPLOS DE IRRELEVANCIA:
- Busco "wireless earbuds" ‚Üí encuentro "USB Cable" ‚Üí IRRELEVANTE
- Busco "lego" ‚Üí encuentro "Libro sobre LEGO" ‚Üí IRRELEVANTE
- Busco "iphone case" ‚Üí encuentro "iPhone charger" ‚Üí IRRELEVANTE
- Busco "gaming mouse" ‚Üí encuentro "Mouse pad" ‚Üí IRRELEVANTE

EJEMPLOS DE RELEVANCIA:
- Busco "wireless earbuds" ‚Üí encuentro "Bluetooth Earbuds XYZ" ‚Üí RELEVANTE
- Busco "lego" ‚Üí encuentro "LEGO Star Wars Set" ‚Üí RELEVANTE
- Busco "iphone case" ‚Üí encuentro "iPhone 15 Pro Case" ‚Üí RELEVANTE

¬øEste producto ES RELEVANTE a la keyword buscada?

Responde SOLO en formato JSON:
{{"is_relevant": true/false, "reason": "explicaci√≥n breve"}}"""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Eres un experto en categorizaci√≥n de productos de e-commerce."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=150
            )

            result_text = response.choices[0].message.content.strip()

            # Parsear respuesta JSON
            import json
            import re
            json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return result.get("is_relevant", True)  # Default: aprobar si hay duda

            return True  # Si falla el parsing, aprobar (evitar falsos negativos)

        except Exception as e:
            # En caso de error, aprobar (evitar bloquear productos por error t√©cnico)
            return True

    def final_ai_validation(
        self,
        candidate_asins: List[str],
        keyword: str
    ) -> Tuple[List[str], dict]:
        """
        VALIDACI√ìN FINAL CON IA: Eval√∫a ASINs UNO POR UNO hasta obtener los N solicitados

        Este es el paso FINAL equivalente al filtro de Wikipedia anterior.
        Va evaluando candidatos en orden BSR (mejor‚Üípeor) hasta obtener
        los N ASINs aprobados (configurado en self.asins_per_keyword).

        EARLY STOPPING: Detiene evaluaci√≥n cuando obtiene suficientes aprobados.

        FILTRO DE MARCA: Si la keyword es una marca conocida (ej: "lego"),
        solo acepta productos de ESA marca espec√≠fica.

        Args:
            candidate_asins: Lista de TODOS los ASINs ordenados por BSR
            keyword: Keyword actual (para logging)

        Returns:
            Tuple[List[str], dict]:
                - Lista de hasta asins_per_keyword ASINs finales aprobados
                - Estad√≠sticas del filtrado
        """
        self.log(f"[5/5] ü§ñ VALIDACI√ìN FINAL IA: Evaluando 1x1 hasta obtener {self.asins_per_keyword} aprobados...", keyword=keyword)

        final_asins = []
        rejected = []
        stats = {
            "total_evaluated": 0,
            "rejected_brand_ai": 0,
            "rejected_safety_ai": 0,
            "rejected_data": 0,
            "approved": 0
        }

        # Evaluar cada candidato final con IA
        for i, asin in enumerate(candidate_asins, 1):
            # Detener si ya tenemos suficientes aprobados
            if len(final_asins) >= self.asins_per_keyword:
                self.log(f"   ‚úÖ Objetivo alcanzado: {self.asins_per_keyword} ASINs aprobados por IA", keyword=keyword)
                self.log(f"   ‚è≠Ô∏è  Deteniendo validaci√≥n (evaluados {i-1}/{len(candidate_asins)})", keyword=keyword)
                break

            stats["total_evaluated"] += 1

            # Obtener datos completos del ASIN
            product_data = {}
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    batch_data = get_products_batch([asin])
                    product_data = batch_data.get(asin, {})
                    time.sleep(2)
                    break
                except Exception as e:
                    if "429" in str(e) and attempt < max_retries - 1:
                        import random
                        wait_time = int(10 * (1.5 ** attempt)) + random.randint(5, 15)
                        self.log(f"   ‚è±Ô∏è Rate limit en {asin}, esperando {wait_time}s...", keyword=keyword)
                        time.sleep(wait_time)
                        continue
                    else:
                        self.log(f"   ‚ö†Ô∏è Error obteniendo {asin}: {e} - SALTANDO", "WARNING", keyword=keyword)
                        break

            if not product_data:
                self.log(f"   ‚ö†Ô∏è [{i}/{len(candidate_asins)}] {asin}: Sin datos - RECHAZADO", keyword=keyword)
                stats["rejected_data"] += 1
                rejected.append({"asin": asin, "reason": "sin_datos"})
                continue

            # Extraer t√≠tulo y marca
            title = ""
            brand = ""
            if "summaries" in product_data and product_data["summaries"]:
                summary = product_data["summaries"][0]
                title = summary.get("itemName", "")
                brand = summary.get("brand", "")

            if not title:
                self.log(f"   ‚ö†Ô∏è [{i}/{len(candidate_asins)}] {asin}: Sin t√≠tulo - RECHAZADO", keyword=keyword)
                stats["rejected_data"] += 1
                rejected.append({"asin": asin, "reason": "sin_titulo"})
                continue

            # FILTRO IA 0: Verificar RELEVANCIA a la keyword
            is_relevant = self._check_relevance_with_ai(title, keyword, brand)
            if not is_relevant:
                self.log(f"   ‚ùå [{i}/{len(candidate_asins)}] {asin}: Rechazado IA - No relevante a '{keyword}'", keyword=keyword)
                stats["rejected_brand_ai"] += 1
                rejected.append({
                    "asin": asin,
                    "reason": "not_relevant",
                    "details": f"Producto no relevante a keyword '{keyword}'"
                })
                continue

            # FILTRO IA 1: BrandIntelligenceFilter (detecta marcas prohibidas + categor√≠as con IA)
            if brand:
                is_safe, reason, filter_details = self.brand_filter.is_brand_safe(title, brand)
                if not is_safe:
                    self.log(f"   ‚ùå [{i}/{len(candidate_asins)}] {asin}: Rechazado IA - {reason}", keyword=keyword)
                    stats["rejected_brand_ai"] += 1
                    rejected.append({
                        "asin": asin,
                        "reason": "brand_intelligence_ai",
                        "details": f"{brand}: {reason}"
                    })
                    continue
                else:
                    self.log(f"   ‚úîÔ∏è  [{i}/{len(candidate_asins)}] {asin}: '{brand}' SAFE IA - {reason}", keyword=keyword)
            else:
                is_safe, reason, filter_details = self.brand_filter.is_brand_safe(title, "")
                if not is_safe:
                    self.log(f"   ‚ùå [{i}/{len(candidate_asins)}] {asin}: Rechazado IA - {reason}", keyword=keyword)
                    stats["rejected_brand_ai"] += 1
                    rejected.append({
                        "asin": asin,
                        "reason": "prohibited_category_ai",
                        "details": reason
                    })
                    continue
                self.log(f"   ‚úîÔ∏è  [{i}/{len(candidate_asins)}] {asin}: Sin marca, t√≠tulo seguro IA", keyword=keyword)

            # FILTRO IA 2: AIProductSafetyFilter (an√°lisis profundo con GPT-4o-mini)
            is_safe, safety_reason, confidence = self.safety_filter.is_safe_to_publish(
                asin, product_data, use_ai=True
            )

            if not is_safe:
                self.log(f"   ‚ùå [{i}/{len(candidate_asins)}] {asin}: Rechazado Safety IA - {safety_reason[:80]}", keyword=keyword)
                stats["rejected_safety_ai"] += 1
                rejected.append({
                    "asin": asin,
                    "reason": "safety_ai",
                    "details": safety_reason
                })
                continue

            # PRODUCTO APROBADO POR IA
            final_asins.append(asin)
            stats["approved"] += 1
            self.log(f"   ‚úÖ [{i}/{len(candidate_asins)}] {asin}: APROBADO IA ({len(final_asins)}/{self.asins_per_keyword})", keyword=keyword)

        # Resumen de validaci√≥n IA
        self.log(f"\n   üìä RESUMEN VALIDACI√ìN FINAL IA:", keyword=keyword)
        self.log(f"      Evaluados con IA: {stats['total_evaluated']}/{len(candidate_asins)}", keyword=keyword)
        self.log(f"      ‚úÖ Aprobados:     {stats['approved']}", keyword=keyword)
        self.log(f"      ‚ùå Marca IA:      {stats['rejected_brand_ai']}", keyword=keyword)
        self.log(f"      ‚ùå Safety IA:     {stats['rejected_safety_ai']}", keyword=keyword)
        self.log(f"      ‚ùå Sin datos:     {stats['rejected_data']}", keyword=keyword)
        self.log(f"   üí∞ Tokens IA: ~{stats['total_evaluated'] * 800} tokens (solo {stats['total_evaluated']} ASINs evaluados)", keyword=keyword)

        return final_asins, stats

    def search_asins_for_keyword(self, keyword: str) -> List[str]:
        """
        Busca ASINs para una keyword y retorna top N por BSR + Validaci√≥n IA final

        NUEVO Proceso OPTIMIZADO (IA solo al final, evaluaci√≥n 1x1):
        1. Busca ~1000 ASINs en Amazon
        2. Filtra por marcas/categor√≠as prohibidas (b√°sico, sin IA)
        3. Filtra por Prime/Fast Fulfillment
        4. Ordena TODOS los ASINs por BSR (mejor‚Üípeor)
        5. VALIDACI√ìN FINAL IA: Eval√∫a 1x1 hasta obtener N aprobados (early stopping)

        Args:
            keyword: Keyword a buscar

        Returns:
            list: Lista de hasta N ASINs aprobados (top por BSR + validados con IA)
        """
        self.log(f"\n{'='*60}")
        self.log(f"üîç Keyword: '{keyword}'")
        self.log(f"{'='*60}")

        try:
            # 1. Buscar en Amazon (100 p√°ginas = ~1000 ASINs)
            self.log(f"[1/5] Buscando en Amazon ({self.search_pages} p√°ginas)...", keyword=keyword)
            all_asins = search_products_by_keyword(
                keyword,
                max_pages=self.search_pages,
                log_callback=lambda msg: self.log(msg, keyword=keyword)
            )
            self.log(f"‚úÖ Encontrados {len(all_asins)} ASINs", keyword=keyword)

            if not all_asins:
                self.log(f"‚ö†Ô∏è No se encontraron ASINs", keyword=keyword)
                return []

            # 2. Filtrar por marcas + categor√≠as prohibidas (SIN IA - solo blacklist b√°sica)
            self.log(f"[2/5] Filtrando por marcas + categor√≠as prohibidas (BATCH API - SIN IA)...", keyword=keyword)
            allowed_asins, rejected = self.filter_asins_by_brand_batch(all_asins, keyword)
            self.log(f"‚úÖ Filtro b√°sico: {len(allowed_asins)}/{len(all_asins)} ASINs permitidos", keyword=keyword)

            if not allowed_asins:
                self.log(f"‚ö†Ô∏è Todos rechazados por filtros b√°sicos", keyword=keyword)
                return []

            # 3. Filtrar por Prime
            self.log(f"[3/5] Filtrando por Prime + Fast Fulfillment...", keyword=keyword)
            prime_asins = self.filter_prime_asins(allowed_asins, keyword)

            if not prime_asins:
                self.log(f"‚ö†Ô∏è Ning√∫n ASIN con Prime", keyword=keyword)
                return []

            self.log(f"‚úÖ {len(prime_asins)} ASINs con Prime (de {len(allowed_asins)} b√°sicos OK)", keyword=keyword)

            # 4. Ordenar TODOS los ASINs por BSR (mejor‚Üípeor)
            self.log(f"[4/5] Ordenando TODOS los ASINs por BSR (mejor‚Üípeor)...", keyword=keyword)
            ranked_asins = self.rank_asins_by_bsr(prime_asins, keyword)

            if not ranked_asins:
                self.log(f"‚ö†Ô∏è No se pudieron ordenar por BSR", keyword=keyword)
                return []

            self.log(f"‚úÖ {len(ranked_asins)} candidatos ordenados por BSR", keyword=keyword)

            # 5. VALIDACI√ìN FINAL IA: Evaluar 1x1 hasta obtener N aprobados
            final_asins, ai_stats = self.final_ai_validation(ranked_asins, keyword)

            if not final_asins:
                self.log(f"‚ö†Ô∏è Ning√∫n ASIN aprob√≥ validaci√≥n IA final", keyword=keyword)
                return []

            # Resumen final
            self.log(f"\n‚úÖ FINAL: {len(final_asins)} ASINs seleccionados", keyword=keyword)
            self.log(f"   üìä Pipeline completo:", keyword=keyword)
            self.log(f"      {len(all_asins)} encontrados Amazon", keyword=keyword)
            self.log(f"      ‚Üí {len(allowed_asins)} filtro b√°sico (sin IA)", keyword=keyword)
            self.log(f"      ‚Üí {len(prime_asins)} Prime OK", keyword=keyword)
            self.log(f"      ‚Üí {len(ranked_asins)} ordenados BSR", keyword=keyword)
            self.log(f"      ‚Üí {ai_stats['total_evaluated']} evaluados IA (early stop)", keyword=keyword)
            self.log(f"      ‚Üí {len(final_asins)} APROBADOS FINALES ‚úÖ", keyword=keyword)
            self.log(f"   üí∞ Ahorro IA: ~{len(all_asins) - ai_stats['total_evaluated']} ASINs NO evaluados (98%+ reducci√≥n)", keyword=keyword)

            return final_asins

        except Exception as e:
            self.log(f"‚ùå Error buscando '{keyword}': {e}", "ERROR", keyword=keyword)
            import traceback
            traceback.print_exc()
            return []

    def save_asins(self, asins: List[str], mode: str = 'a'):
        """
        Guarda ASINs en asins.txt

        Args:
            asins: Lista de ASINs
            mode: 'w' = sobrescribir, 'a' = append
        """
        with open(self.output_file, mode, encoding='utf-8') as f:
            for asin in asins:
                f.write(f"{asin}\n")

        self.log(f"üíæ {len(asins)} ASINs guardados en {self.output_file}")

    def run(self):
        """Ejecuta la b√∫squeda para todas las keywords"""

        # Limpiar archivo de salida
        if self.output_file.exists():
            self.output_file.unlink()
            self.log(f"üóëÔ∏è  Limpiado {self.output_file}")

        # Cargar keywords
        keywords = self.load_keywords()

        if not keywords:
            self.log("‚ùå No hay keywords para procesar", "ERROR")
            return

        self.log(f"\nüöÄ Iniciando b√∫squeda de {len(keywords)} keywords...")
        self.log(f"   Target total: {len(keywords)} √ó {self.asins_per_keyword} = {len(keywords) * self.asins_per_keyword} ASINs")

        # Procesar cada keyword
        all_asins = []

        for i, keyword in enumerate(keywords, 1):
            self.log(f"\n{'#'*60}")
            self.log(f"Keyword {i}/{len(keywords)}")
            self.log(f"{'#'*60}")

            asins = self.search_asins_for_keyword(keyword)

            if asins:
                all_asins.extend(asins)
                self.total_keywords_processed += 1
                self.total_asins_found += len(asins)

                # Guardar inmediatamente (append)
                self.save_asins(asins, mode='a')
            else:
                self.log(f"‚ö†Ô∏è No se encontraron ASINs para '{keyword}'")

            # Peque√±o delay entre keywords
            if i < len(keywords):
                self.log(f"‚è±Ô∏è  Esperando 10 segundos antes de siguiente keyword...")
                time.sleep(10)

        # Resumen final
        elapsed = (datetime.now() - self.start_time).total_seconds() / 60

        self.log(f"\n{'='*60}")
        self.log("‚úÖ B√öSQUEDA COMPLETADA")
        self.log(f"{'='*60}")
        self.log(f"üìä RESUMEN:")
        self.log(f"   Keywords procesadas:  {self.total_keywords_processed}/{len(keywords)}")
        self.log(f"   ASINs encontrados:    {self.total_asins_found}")
        self.log(f"   Promedio por keyword: {self.total_asins_found / max(self.total_keywords_processed, 1):.1f} ASINs")
        self.log(f"   Tiempo total:         {elapsed:.1f} minutos ({elapsed/60:.1f} horas)")
        self.log(f"   Output:               {self.output_file}")
        self.log(f"{'='*60}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="B√∫squeda: Top 12 ASINs por BSR para cada keyword"
    )
    parser.add_argument(
        '--keywords-file',
        type=str,
        help='Path al archivo de keywords (default: ~/Desktop/asins-1000.txt)'
    )
    parser.add_argument(
        '--output-file',
        type=str,
        help='Path al archivo de salida (default: asins.txt)'
    )
    parser.add_argument(
        '--asins-per-keyword',
        type=int,
        default=8,
        help='N√∫mero de ASINs por keyword (default: 8)'
    )
    parser.add_argument(
        '--process-id',
        type=int,
        help='ID del proceso (para parallel search)'
    )

    args = parser.parse_args()

    try:
        searcher = SimpleKeywordSearch(
            keywords_file=args.keywords_file,
            output_file=args.output_file,
            asins_per_keyword=args.asins_per_keyword,
            process_id=args.process_id if args.process_id is not None else 0
        )
        searcher.run()

    except KeyboardInterrupt:
        print("\n\nüõë B√∫squeda detenida por usuario (Ctrl+C)")
        sys.exit(0)

    except Exception as e:
        print(f"\n‚ùå Error fatal: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
