#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
main2.py - Pipeline Profesional Amazon ‚Üí MercadoLibre CBT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Pipeline completo con validaci√≥n IA, retry inteligente y tracking de estado.

Flujo optimizado:
1. Pre-flight checks (credenciales, conexi√≥n, rate limits)
2. Download: Descarga datos de Amazon SP-API con retry
3. Transform: Transforma con IA + validaci√≥n completa
4. Validate: Validaci√≥n IA de im√°genes y categor√≠as
5. Publish: Publicaci√≥n en MercadoLibre CBT con retry inteligente
6. Sync: Sincronizaci√≥n multi-marketplace

Caracter√≠sticas:
- ‚úÖ Validaci√≥n IA pre-publicaci√≥n (im√°genes + categor√≠as)
- ‚úÖ Retry inteligente con estrategias diferentes
- ‚úÖ Base de datos SQLite para tracking
- ‚úÖ Health checks autom√°ticos
- ‚úÖ Rate limiting inteligente
- ‚úÖ Logs detallados por fase
- ‚úÖ Modo dry-run para testing
- ‚úÖ Recuperaci√≥n de errores autom√°tica
- ‚úÖ Reportes detallados con estad√≠sticas

Autor: Pipeline v2.0 Optimizado
Fecha: 2025-01-03
"""

import os
import sys
import json
import time
import sqlite3
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from enum import Enum
from dotenv import load_dotenv
import traceback

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# AUTO-ACTIVACI√ìN DE VENV
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

if sys.prefix == sys.base_prefix:
    vpy = Path(__file__).parent / "venv" / "bin" / "python"
    if vpy.exists():
        print(f"‚öôÔ∏è  Activando entorno virtual: {vpy}")
        os.execv(str(vpy), [str(vpy)] + sys.argv)

load_dotenv(override=True)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# IMPORTS DE M√ìDULOS PROPIOS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

from src.amazon_api import get_product_data_from_asin
from src.transform_mapper_new import build_mini_ml, load_json_file, save_json_file
from src.unified_transformer import transform_amazon_to_ml_unified
from src.ai_validators import validate_listing_complete
from src.smart_categorizer import categorize_with_ai
from src.mainglobal import publish_item

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CONFIGURACI√ìN
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class Config:
    """Configuraci√≥n centralizada del pipeline"""

    # Directorios
    ASINS_FILE = Path("resources/asins.txt")
    AMAZON_JSON_DIR = Path("storage/asins_json")
    MINI_ML_DIR = Path("storage/logs/publish_ready")
    OUTPUT_JSON_DIR = Path("outputs/json")
    LOGS_DIR = Path("storage/logs/pipeline")
    DB_PATH = Path("storage/pipeline_state.db")
    GTIN_ISSUES_LOG = Path("storage/logs/gtin_issues.json")

    # Retry configuration
    MAX_DOWNLOAD_RETRIES = 3
    MAX_TRANSFORM_RETRIES = 2
    MAX_PUBLISH_RETRIES = 3

    # Delays (seconds)
    RETRY_DELAY = 5
    PUBLISH_DELAY = 3
    RATE_LIMIT_DELAY = 10

    # Flags
    DRY_RUN = False
    SKIP_VALIDATION = True  # Validaci√≥n IA desactivada por defecto
    FORCE_REGENERATE = True  # SIEMPRE regenerar, NO usar cach√©

    @classmethod
    def setup_directories(cls):
        """Crea todos los directorios necesarios"""
        for path in [cls.AMAZON_JSON_DIR, cls.MINI_ML_DIR,
                     cls.OUTPUT_JSON_DIR, cls.LOGS_DIR]:
            path.mkdir(parents=True, exist_ok=True)
        cls.DB_PATH.parent.mkdir(parents=True, exist_ok=True)


class Status(Enum):
    """Estados del pipeline"""
    PENDING = "pending"
    DOWNLOADING = "downloading"
    DOWNLOADED = "downloaded"
    TRANSFORMING = "transforming"
    TRANSFORMED = "transformed"
    VALIDATING = "validating"
    VALIDATED = "validated"
    PUBLISHING = "publishing"
    PUBLISHED = "published"
    FAILED = "failed"
    SKIPPED = "skipped"


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# BASE DE DATOS Y TRACKING
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class PipelineDB:
    """Gesti√≥n de base de datos para tracking del pipeline"""

    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.init_database()

    def init_database(self):
        """Inicializa la base de datos y tablas"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS pipeline_runs (
                run_id TEXT PRIMARY KEY,
                started_at TEXT,
                completed_at TEXT,
                total_asins INTEGER,
                success_count INTEGER,
                failed_count INTEGER,
                status TEXT
            )
        """)

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS asin_status (
                asin TEXT PRIMARY KEY,
                status TEXT,
                last_error TEXT,
                retry_count INTEGER DEFAULT 0,
                download_attempts INTEGER DEFAULT 0,
                transform_attempts INTEGER DEFAULT 0,
                publish_attempts INTEGER DEFAULT 0,
                item_id TEXT,
                created_at TEXT,
                updated_at TEXT
            )
        """)

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                asin TEXT,
                phase TEXT,
                message TEXT,
                level TEXT,
                timestamp TEXT
            )
        """)

        conn.commit()
        conn.close()

    def create_run(self, run_id: str, total_asins: int) -> None:
        """Crea un nuevo registro de ejecuci√≥n"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            INSERT OR REPLACE INTO pipeline_runs
            (run_id, started_at, total_asins, success_count, failed_count, status)
            VALUES (?, ?, ?, 0, 0, 'running')
        """, (run_id, datetime.now().isoformat(), total_asins))

        conn.commit()
        conn.close()

    def update_asin_status(self, asin: str, status: Status,
                          error: Optional[str] = None,
                          item_id: Optional[str] = None) -> None:
        """Actualiza el estado de un ASIN"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            INSERT INTO asin_status (asin, status, last_error, item_id, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, ?)
            ON CONFLICT(asin) DO UPDATE SET
                status = excluded.status,
                last_error = excluded.last_error,
                item_id = excluded.item_id,
                updated_at = excluded.updated_at
        """, (asin, status.value, error, item_id,
              datetime.now().isoformat(), datetime.now().isoformat()))

        conn.commit()
        conn.close()

    def increment_retry(self, asin: str, phase: str) -> int:
        """Incrementa el contador de reintentos y retorna el nuevo valor"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        field = f"{phase}_attempts"
        cursor.execute(f"""
            UPDATE asin_status
            SET {field} = {field} + 1,
                retry_count = retry_count + 1,
                updated_at = ?
            WHERE asin = ?
        """, (datetime.now().isoformat(), asin))

        cursor.execute(f"""
            SELECT {field} FROM asin_status WHERE asin = ?
        """, (asin,))

        result = cursor.fetchone()
        conn.commit()
        conn.close()

        return result[0] if result else 0

    def log(self, asin: str, phase: str, message: str, level: str = "INFO") -> None:
        """Registra un log en la base de datos"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            INSERT INTO logs (asin, phase, message, level, timestamp)
            VALUES (?, ?, ?, ?, ?)
        """, (asin, phase, message, level, datetime.now().isoformat()))

        conn.commit()
        conn.close()

    def get_asin_status(self, asin: str) -> Optional[Dict]:
        """Obtiene el estado actual de un ASIN"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT asin, status, last_error, retry_count, item_id
            FROM asin_status WHERE asin = ?
        """, (asin,))

        result = cursor.fetchone()
        conn.close()

        if result:
            return {
                "asin": result[0],
                "status": result[1],
                "last_error": result[2],
                "retry_count": result[3],
                "item_id": result[4]
            }
        return None

    def get_statistics(self) -> Dict:
        """Obtiene estad√≠sticas del pipeline"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT status, COUNT(*)
            FROM asin_status
            GROUP BY status
        """)

        stats = {row[0]: row[1] for row in cursor.fetchall()}
        conn.close()

        return stats


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# GTIN ISSUES LOGGING
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def log_gtin_issue(asin: str, gtin: str, category_id: str, error_code: str, error_message: str, mini_ml_data: dict = None):
    """
    Registra productos que no se pueden publicar por problemas con GTIN.

    Args:
        asin: El ASIN del producto
        gtin: El GTIN que caus√≥ el problema (puede ser None)
        category_id: Categor√≠a en la que se intent√≥ publicar
        error_code: C√≥digo de error de MercadoLibre (ej: "3701", "7810")
        error_message: Mensaje de error completo
        mini_ml_data: Datos completos del mini_ml para referencia
    """
    from datetime import datetime

    log_file = Config.GTIN_ISSUES_LOG

    # Cargar log existente o crear nuevo
    if log_file.exists():
        with open(log_file, 'r', encoding='utf-8') as f:
            try:
                issues = json.load(f)
            except json.JSONDecodeError:
                issues = []
    else:
        issues = []

    # Agregar nuevo issue
    issue_entry = {
        "asin": asin,
        "gtin": gtin,
        "category_id": category_id,
        "category_name": mini_ml_data.get("category_name") if mini_ml_data else None,
        "error_code": error_code,
        "error_message": error_message,
        "timestamp": datetime.now().isoformat(),
        "product_title": mini_ml_data.get("title_ai") if mini_ml_data else None,
        "brand": mini_ml_data.get("brand") if mini_ml_data else None,
        "price": mini_ml_data.get("price") if mini_ml_data else None
    }

    issues.append(issue_entry)

    # Guardar log actualizado
    log_file.parent.mkdir(parents=True, exist_ok=True)
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(issues, f, indent=2, ensure_ascii=False)

    print(f"üìù Problema GTIN registrado: {asin} (error {error_code})")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# HEALTH CHECKS Y PRE-FLIGHT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class HealthChecker:
    """Verificaci√≥n de salud del sistema antes de iniciar"""

    @staticmethod
    def check_credentials() -> Tuple[bool, List[str]]:
        """Verifica que todas las credenciales necesarias est√©n configuradas"""
        errors = []

        if not os.getenv("ML_ACCESS_TOKEN"):
            errors.append("‚ùå Falta ML_ACCESS_TOKEN en .env")

        if not os.getenv("AMZ_CLIENT_ID"):
            errors.append("‚ùå Faltan credenciales de Amazon SP-API")

        if not os.getenv("OPENAI_API_KEY"):
            errors.append("‚ö†Ô∏è  Sin OPENAI_API_KEY (algunas funciones IA no estar√°n disponibles)")

        return len(errors) == 0, errors

    @staticmethod
    def check_api_connectivity() -> Tuple[bool, List[str]]:
        """Verifica conectividad con APIs"""
        import requests
        errors = []

        # Check MercadoLibre API
        try:
            token = os.getenv("ML_ACCESS_TOKEN")
            response = requests.get(
                "https://api.mercadolibre.com/users/me",
                headers={"Authorization": f"Bearer {token}"},
                timeout=10
            )
            if response.status_code != 200:
                errors.append(f"‚ùå ML API error: {response.status_code}")
        except Exception as e:
            errors.append(f"‚ùå No se puede conectar a ML API: {e}")

        # Check OpenAI API
        if os.getenv("OPENAI_API_KEY"):
            try:
                from openai import OpenAI
                client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                # Simple test call
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": "test"}],
                    max_tokens=5
                )
                if not response:
                    errors.append("‚ùå OpenAI API no responde correctamente")
            except Exception as e:
                errors.append(f"‚ùå Error OpenAI API: {e}")

        return len(errors) == 0, errors

    @staticmethod
    def run_all_checks() -> bool:
        """Ejecuta todas las verificaciones de salud"""
        print("\n" + "="*70)
        print("üè• PRE-FLIGHT HEALTH CHECKS")
        print("="*70 + "\n")

        all_ok = True

        # Check credentials
        print("üîë Verificando credenciales...")
        creds_ok, creds_errors = HealthChecker.check_credentials()
        if creds_ok:
            print("   ‚úÖ Todas las credenciales configuradas")
        else:
            all_ok = False
            for error in creds_errors:
                print(f"   {error}")

        # Check API connectivity
        print("\nüåê Verificando conectividad API...")
        api_ok, api_errors = HealthChecker.check_api_connectivity()
        if api_ok:
            print("   ‚úÖ Todas las APIs disponibles")
        else:
            all_ok = False
            for error in api_errors:
                print(f"   {error}")

        # Check directories
        print("\nüìÅ Verificando directorios...")
        Config.setup_directories()
        print("   ‚úÖ Todos los directorios creados")

        print("\n" + "="*70)
        if all_ok:
            print("‚úÖ TODOS LOS CHECKS PASARON - SISTEMA LISTO")
        else:
            print("‚ùå ALGUNOS CHECKS FALLARON - REVISAR CONFIGURACI√ìN")
        print("="*70 + "\n")

        return all_ok


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PIPELINE PHASES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class PipelinePhase:
    """Clase base para las fases del pipeline"""

    def __init__(self, db: PipelineDB):
        self.db = db

    def log(self, asin: str, message: str, level: str = "INFO"):
        """Log helper"""
        phase = self.__class__.__name__.replace("Phase", "").lower()
        self.db.log(asin, phase, message, level)

        # Tambi√©n imprimir en consola
        icon = {"INFO": "‚ÑπÔ∏è", "ERROR": "‚ùå", "WARNING": "‚ö†Ô∏è", "SUCCESS": "‚úÖ"}.get(level, "üìù")
        print(f"{icon} [{phase}] {asin}: {message}")


class DownloadPhase(PipelinePhase):
    """Fase de descarga desde Amazon SP-API"""

    def execute(self, asin: str) -> bool:
        """Descarga datos de Amazon para un ASIN"""
        json_path = Config.AMAZON_JSON_DIR / f"{asin}.json"

        # Si ya existe y no es force regenerate, skip
        if json_path.exists() and not Config.FORCE_REGENERATE:
            self.log(asin, "Ya descargado, saltando...", "INFO")
            self.db.update_asin_status(asin, Status.DOWNLOADED)
            return True

        max_retries = Config.MAX_DOWNLOAD_RETRIES

        for attempt in range(1, max_retries + 1):
            try:
                self.db.update_asin_status(asin, Status.DOWNLOADING)
                retry_num = self.db.increment_retry(asin, "download")

                if attempt > 1:
                    self.log(asin, f"Reintento {attempt}/{max_retries}", "WARNING")
                    time.sleep(Config.RETRY_DELAY * attempt)  # Exponential backoff

                self.log(asin, "Descargando desde Amazon SP-API...", "INFO")
                get_product_data_from_asin(asin, save_path=str(json_path))

                if json_path.exists():
                    self.log(asin, "Descarga exitosa", "SUCCESS")
                    self.db.update_asin_status(asin, Status.DOWNLOADED)
                    return True
                else:
                    raise Exception("Archivo no creado despu√©s de descarga")

            except Exception as e:
                error_msg = str(e)
                self.log(asin, f"Error en intento {attempt}: {error_msg}", "ERROR")

                if attempt == max_retries:
                    self.db.update_asin_status(asin, Status.FAILED, error_msg)
                    return False

        return False


class TransformPhase(PipelinePhase):
    """Fase de transformaci√≥n de Amazon a MercadoLibre"""

    def execute(self, asin: str) -> bool:
        """Transforma JSON de Amazon a mini_ml"""
        amazon_path = Config.AMAZON_JSON_DIR / f"{asin}.json"
        mini_path = Config.MINI_ML_DIR / f"{asin}_mini_ml.json"

        # Validar que existe el archivo de Amazon
        if not amazon_path.exists():
            self.log(asin, "No existe JSON de Amazon", "ERROR")
            self.db.update_asin_status(asin, Status.FAILED, "Missing Amazon JSON")
            return False

        # Si ya existe y no es force regenerate, skip
        if mini_path.exists() and not Config.FORCE_REGENERATE:
            self.log(asin, "Ya transformado, saltando...", "INFO")
            self.db.update_asin_status(asin, Status.TRANSFORMED)
            return True

        max_retries = Config.MAX_TRANSFORM_RETRIES

        for attempt in range(1, max_retries + 1):
            try:
                self.db.update_asin_status(asin, Status.TRANSFORMING)
                retry_num = self.db.increment_retry(asin, "transform")

                if attempt > 1:
                    self.log(asin, f"Reintento transformaci√≥n {attempt}/{max_retries}", "WARNING")
                    time.sleep(Config.RETRY_DELAY)

                self.log(asin, "Cargando JSON de Amazon...", "INFO")
                amazon_json = load_json_file(str(amazon_path))

                # Intentar transformaci√≥n unificada con IA primero
                self.log(asin, "Transformando con IA unificada...", "INFO")
                mini_ml = build_mini_ml(amazon_json)

                if not mini_ml:
                    raise Exception("build_mini_ml retorn√≥ None")

                # Validar que tenga campos b√°sicos
                if not mini_ml.get("title_ai") and not mini_ml.get("title"):
                    raise Exception("Mini ML sin t√≠tulo")

                if not mini_ml.get("category_id"):
                    raise Exception("Mini ML sin categor√≠a")

                # Guardar mini_ml
                save_json_file(str(mini_path), mini_ml)

                # Tambi√©n copiar a outputs/json para compatibilidad
                output_path = Config.OUTPUT_JSON_DIR / f"{asin}.json"
                save_json_file(str(output_path), amazon_json)

                self.log(asin, f"Transformaci√≥n completa: {mini_ml.get('category_id')}", "SUCCESS")
                self.log(asin, f"  ‚Üí Atributos: {len(mini_ml.get('attributes_mapped', {}))}", "INFO")
                self.log(asin, f"  ‚Üí Im√°genes: {len(mini_ml.get('images', []))}", "INFO")

                self.db.update_asin_status(asin, Status.TRANSFORMED)
                return True

            except Exception as e:
                error_msg = str(e)
                self.log(asin, f"Error transformaci√≥n: {error_msg}", "ERROR")

                if attempt == max_retries:
                    self.db.update_asin_status(asin, Status.FAILED, error_msg)
                    return False

        return False


class ValidationPhase(PipelinePhase):
    """Fase de validaci√≥n IA pre-publicaci√≥n"""

    def execute(self, asin: str) -> bool:
        """Valida listing con IA antes de publicar"""
        mini_path = Config.MINI_ML_DIR / f"{asin}_mini_ml.json"

        if not mini_path.exists():
            self.log(asin, "No existe mini_ml para validar", "ERROR")
            return False

        # Si se skipea validaci√≥n (para testing r√°pido)
        if Config.SKIP_VALIDATION:
            self.log(asin, "Validaci√≥n IA omitida (skip flag activo)", "WARNING")
            self.db.update_asin_status(asin, Status.VALIDATED)
            return True

        try:
            self.db.update_asin_status(asin, Status.VALIDATING)
            self.log(asin, "Ejecutando validaci√≥n IA completa...", "INFO")

            mini_ml = load_json_file(str(mini_path))

            # Validaci√≥n IA completa
            validation_result = validate_listing_complete(mini_ml)

            if not validation_result["ready_to_publish"]:
                self.log(asin, "Validaci√≥n FALLIDA", "ERROR")

                # Registrar problemas
                issues = []
                if validation_result["critical_issues"]:
                    for issue in validation_result["critical_issues"]:
                        self.log(asin, f"  CR√çTICO: {issue}", "ERROR")
                        issues.append(issue)

                if validation_result["warnings"]:
                    for warning in validation_result["warnings"]:
                        self.log(asin, f"  WARNING: {warning}", "WARNING")
                        issues.append(warning)

                # Guardar error
                error_msg = "; ".join(issues[:3])  # Primeros 3 issues
                self.db.update_asin_status(asin, Status.FAILED, f"Validation: {error_msg}")
                return False

            # Validaci√≥n exitosa
            img_val = validation_result.get("image_validation", {})
            cat_val = validation_result.get("category_validation", {})

            self.log(asin, "Validaci√≥n IA: APROBADO", "SUCCESS")
            self.log(asin, f"  ‚Üí Im√°genes: {'‚úÖ' if img_val.get('valid') else '‚ùå'}", "INFO")
            self.log(asin, f"  ‚Üí Categor√≠a: {'‚úÖ' if cat_val.get('valid') else '‚ùå'} ({cat_val.get('confidence', 0):.0%})", "INFO")

            self.db.update_asin_status(asin, Status.VALIDATED)
            return True

        except Exception as e:
            error_msg = str(e)
            self.log(asin, f"Error en validaci√≥n: {error_msg}", "ERROR")
            self.db.update_asin_status(asin, Status.FAILED, error_msg)
            return False


class PublishPhase(PipelinePhase):
    """Fase de publicaci√≥n en MercadoLibre CBT"""

    def execute(self, asin: str) -> Optional[str]:
        """Publica producto en MercadoLibre CBT"""
        mini_path = Config.MINI_ML_DIR / f"{asin}_mini_ml.json"

        if not mini_path.exists():
            self.log(asin, "No existe mini_ml para publicar", "ERROR")
            return None

        # Modo dry-run
        if Config.DRY_RUN:
            self.log(asin, "DRY RUN - Publicaci√≥n simulada (no se envi√≥ a ML)", "WARNING")
            self.db.update_asin_status(asin, Status.PUBLISHED, item_id="DRY_RUN")
            return "DRY_RUN_ID"

        max_retries = Config.MAX_PUBLISH_RETRIES

        for attempt in range(1, max_retries + 1):
            try:
                self.db.update_asin_status(asin, Status.PUBLISHING)
                retry_num = self.db.increment_retry(asin, "publish")

                if attempt > 1:
                    self.log(asin, f"Reintento publicaci√≥n {attempt}/{max_retries}", "WARNING")
                    time.sleep(Config.RETRY_DELAY * attempt)

                self.log(asin, "Cargando mini_ml...", "INFO")
                mini_ml = load_json_file(str(mini_path))

                self.log(asin, "Publicando en MercadoLibre CBT...", "INFO")
                result = publish_item(mini_ml)

                # Verificar resultado
                if result is None:
                    raise Exception("Publicaci√≥n abortada (dimensiones/im√°genes inv√°lidas)")

                # Obtener item_id
                item_id = result.get("item_id") or result.get("id")

                if item_id:
                    self.log(asin, f"Publicado exitosamente: {item_id}", "SUCCESS")

                    # Informaci√≥n adicional
                    site_items = result.get("site_items", [])
                    successful = [s for s in site_items if s.get("item_id")]
                    failed = [s for s in site_items if s.get("error")]

                    self.log(asin, f"  ‚Üí Publicado en {len(successful)} pa√≠ses", "INFO")
                    if failed:
                        self.log(asin, f"  ‚Üí {len(failed)} pa√≠ses con errores", "WARNING")

                    self.db.update_asin_status(asin, Status.PUBLISHED, item_id=item_id)
                    return item_id
                else:
                    raise Exception(f"Publicaci√≥n sin ID: {result}")

            except Exception as e:
                error_str = str(e)
                self.log(asin, f"Error publicaci√≥n: {error_str}", "ERROR")

                # Detectar errores espec√≠ficos y aplicar estrategias

                # Error de GTIN duplicado (c√≥digo 3701) - Intentar sin GTIN
                if "3701" in error_str or "invalid_product_identifier" in error_str:
                    mini_ml = load_json_file(str(mini_path))

                    # Si ya intentamos sin GTIN y sigue fallando, registrar y abortar
                    if mini_ml.get("force_no_gtin"):
                        self.log(asin, "‚ùå GTIN duplicado y sin GTIN tambi√©n rechazado ‚Üí Guardando en log", "ERROR")

                        log_gtin_issue(
                            asin=asin,
                            gtin=mini_ml.get("gtin"),
                            category_id=mini_ml.get("category_id"),
                            error_code="3701",
                            error_message="GTIN duplicado - ya usado. Intent√≥ sin GTIN pero tambi√©n rechazado",
                            mini_ml_data=mini_ml
                        )

                        self.db.update_asin_status(asin, Status.FAILED, "GTIN duplicated and no-GTIN also rejected")
                        return None

                    # Primer intento: marcar force_no_gtin y reintentar
                    self.log(asin, "‚ö†Ô∏è GTIN duplicado ‚Üí Reintentando SIN GTIN", "WARNING")
                    mini_ml["force_no_gtin"] = True
                    mini_ml["last_error"] = "GTIN_REUSED"
                    save_json_file(str(mini_path), mini_ml)
                    continue  # Reintentar

                # Error 7810: GTIN requerido pero no disponible - Intentar sin GTIN
                if "7810" in error_str or ("missing_conditional_required" in error_str and "GTIN" in error_str):
                    mini_ml = load_json_file(str(mini_path))

                    # Si ya intentamos sin GTIN y sigue fallando, registrar y abortar
                    if mini_ml.get("force_no_gtin"):
                        self.log(asin, "‚ùå Categor√≠a requiere GTIN y sin GTIN tambi√©n rechazado ‚Üí Guardando en log", "ERROR")

                        log_gtin_issue(
                            asin=asin,
                            gtin=mini_ml.get("gtin"),
                            category_id=mini_ml.get("category_id"),
                            error_code="7810",
                            error_message="Categor√≠a requiere GTIN. Intent√≥ sin GTIN pero tambi√©n rechazado",
                            mini_ml_data=mini_ml
                        )

                        self.db.update_asin_status(asin, Status.FAILED, "Category requires GTIN - no alternatives work")
                        return None

                    # Primer intento: marcar force_no_gtin y reintentar
                    self.log(asin, "‚ö†Ô∏è Categor√≠a requiere GTIN ‚Üí Reintentando SIN GTIN", "WARNING")
                    mini_ml["force_no_gtin"] = True
                    mini_ml["last_error"] = "GTIN_REQUIRED"
                    save_json_file(str(mini_path), mini_ml)
                    continue  # Reintentar

                # Error de categor√≠a incorrecta
                if "category" in error_str.lower() or "Title and photos did not match" in error_str:
                    self.log(asin, "Categor√≠a incorrecta ‚Üí Regenerando con nueva categor√≠a", "WARNING")
                    # Eliminar mini_ml y marcar para regeneraci√≥n
                    mini_path.unlink()
                    self.db.update_asin_status(asin, Status.DOWNLOADED)  # Volver a transformar
                    return None

                # Error de rate limiting
                if "429" in error_str or "rate" in error_str.lower():
                    self.log(asin, f"Rate limited ‚Üí Esperando {Config.RATE_LIMIT_DELAY}s", "WARNING")
                    time.sleep(Config.RATE_LIMIT_DELAY)
                    continue

                # Si es el √∫ltimo intento, fallar
                if attempt == max_retries:
                    self.db.update_asin_status(asin, Status.FAILED, error_str[:500])
                    return None

        return None


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PIPELINE ORCHESTRATOR
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class Pipeline:
    """Orquestador principal del pipeline"""

    def __init__(self, config: Config):
        self.config = config
        self.db = PipelineDB(config.DB_PATH)

        # Inicializar fases
        self.download_phase = DownloadPhase(self.db)
        self.transform_phase = TransformPhase(self.db)
        self.validation_phase = ValidationPhase(self.db)
        self.publish_phase = PublishPhase(self.db)

        self.run_id = datetime.now().strftime("%Y%m%d_%H%M%S")

    def load_asins(self) -> List[str]:
        """Carga lista de ASINs desde archivo"""
        if not Config.ASINS_FILE.exists():
            print(f"‚ùå No se encontr√≥ el archivo {Config.ASINS_FILE}")
            return []

        with open(Config.ASINS_FILE, "r") as f:
            asins = [
                line.strip().upper()
                for line in f
                if line.strip() and not line.startswith("#")
            ]

        print(f"üìã {len(asins)} ASINs cargados desde {Config.ASINS_FILE}")
        return asins

    def process_asin(self, asin: str, index: int, total: int) -> Dict:
        """Procesa un ASIN completo a trav√©s de todas las fases"""

        print(f"\n{'='*70}")
        print(f"üì¶ Procesando [{index}/{total}]: {asin}")
        print(f"{'='*70}")

        result = {
            "asin": asin,
            "success": False,
            "item_id": None,
            "phase": None
        }

        # Fase 1: Download
        if not self.download_phase.execute(asin):
            result["phase"] = "download"
            return result

        # Fase 2: Transform
        if not self.transform_phase.execute(asin):
            result["phase"] = "transform"
            return result

        # Fase 3: Validation
        if not self.validation_phase.execute(asin):
            result["phase"] = "validation"
            return result

        # Fase 4: Publish
        item_id = self.publish_phase.execute(asin)
        if item_id:
            result["success"] = True
            result["item_id"] = item_id
            result["phase"] = "published"
        else:
            result["phase"] = "publish"

        return result

    def run(self, asins: List[str]) -> Dict:
        """Ejecuta el pipeline completo para todos los ASINs"""

        if not asins:
            print("‚ùå No hay ASINs para procesar")
            return {"success": 0, "failed": 0}

        # Crear registro de ejecuci√≥n
        self.db.create_run(self.run_id, len(asins))

        print("\n" + "="*70)
        print("üöÄ INICIANDO PIPELINE AMAZON ‚Üí MERCADOLIBRE CBT v2.0")
        print("="*70)
        print(f"üì¶ Total de productos: {len(asins)}")
        print(f"üÜî Run ID: {self.run_id}")
        if Config.DRY_RUN:
            print("‚ö†Ô∏è  MODO DRY-RUN ACTIVO (no se publicar√° realmente)")
        if Config.SKIP_VALIDATION:
            print("‚ö†Ô∏è  VALIDACI√ìN IA DESACTIVADA")
        print("="*70 + "\n")

        results = {
            "success": [],
            "failed": [],
            "skipped": []
        }

        start_time = time.time()

        for i, asin in enumerate(asins, 1):
            try:
                result = self.process_asin(asin, i, len(asins))

                if result["success"]:
                    results["success"].append(asin)
                else:
                    results["failed"].append(asin)

                # Rate limiting entre productos
                if i < len(asins) and not Config.DRY_RUN:
                    print(f"\n‚è±Ô∏è  Esperando {Config.PUBLISH_DELAY}s antes del siguiente producto...")
                    time.sleep(Config.PUBLISH_DELAY)

            except KeyboardInterrupt:
                print("\n\n‚ö†Ô∏è  Pipeline interrumpido por el usuario")
                break
            except Exception as e:
                print(f"\n‚ùå Error cr√≠tico procesando {asin}: {e}")
                traceback.print_exc()
                results["failed"].append(asin)

        # Calcular tiempo total
        elapsed_time = time.time() - start_time

        # Reporte final
        self.print_final_report(results, elapsed_time)

        return results

    def print_final_report(self, results: Dict, elapsed_time: float):
        """Imprime reporte final detallado"""

        total = len(results["success"]) + len(results["failed"]) + len(results["skipped"])

        print("\n" + "="*70)
        print("üìä REPORTE FINAL DEL PIPELINE")
        print("="*70)
        print(f"‚è±Ô∏è  Tiempo total: {elapsed_time/60:.1f} minutos")
        print(f"üì¶ Total procesados: {total}")
        print(f"‚úÖ Exitosos: {len(results['success'])}/{total} ({len(results['success'])/total*100:.1f}%)")
        print(f"‚ùå Fallidos: {len(results['failed'])}/{total} ({len(results['failed'])/total*100:.1f}%)")

        if results["skipped"]:
            print(f"‚è≠Ô∏è  Saltados: {len(results['skipped'])}/{total}")

        # Estad√≠sticas de la base de datos
        stats = self.db.get_statistics()
        print(f"\nüìà ESTAD√çSTICAS POR ESTADO:")
        for status, count in stats.items():
            print(f"   {status}: {count}")

        if results["failed"]:
            print(f"\n‚ö†Ô∏è  ASINs fallidos:")
            for asin in results["failed"][:10]:  # Mostrar m√°ximo 10
                status = self.db.get_asin_status(asin)
                if status:
                    error = status.get("last_error") or "Unknown"
                    error = str(error)[:50]  # Convertir a string y limitar a 50 chars
                    print(f"   ‚Ä¢ {asin}: {error}")

            if len(results["failed"]) > 10:
                print(f"   ... y {len(results['failed']) - 10} m√°s")

        print("\n" + "="*70)
        print("‚úÖ PIPELINE COMPLETADO")
        print("="*70 + "\n")

        # Guardar reporte en archivo
        report_path = Config.LOGS_DIR / f"report_{self.run_id}.json"
        with open(report_path, "w") as f:
            json.dump({
                "run_id": self.run_id,
                "timestamp": datetime.now().isoformat(),
                "elapsed_seconds": elapsed_time,
                "results": results,
                "statistics": stats
            }, f, indent=2)

        print(f"üìÑ Reporte guardado en: {report_path}\n")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MAIN
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def main():
    """Punto de entrada principal"""

    # Parse command line arguments
    import argparse
    parser = argparse.ArgumentParser(description="Pipeline Amazon ‚Üí MercadoLibre CBT v2.0")
    parser.add_argument("--dry-run", action="store_true", help="Simular publicaciones sin enviar a ML")
    parser.add_argument("--enable-validation", action="store_true", help="Activar validaci√≥n IA (est√° desactivada por defecto)")
    parser.add_argument("--force-regenerate", action="store_true", help="Forzar regeneraci√≥n de archivos existentes")
    parser.add_argument("--skip-health-check", action="store_true", help="Saltar verificaciones de salud")
    parser.add_argument("--asin", type=str, help="Procesar solo un ASIN espec√≠fico")
    parser.add_argument("--asins-file", type=str, help="Archivo con lista de ASINs (default: resources/asins.txt)")

    args = parser.parse_args()

    # Configurar flags
    Config.DRY_RUN = args.dry_run
    # Si se pasa --enable-validation, activar (SKIP_VALIDATION = False)
    if args.enable_validation:
        Config.SKIP_VALIDATION = False
    # De lo contrario, mantener el default de Config (True)
    # Solo sobrescribir FORCE_REGENERATE si se pasa el flag expl√≠citamente
    if args.force_regenerate:
        Config.FORCE_REGENERATE = True
    # De lo contrario, mantener el default de Config class (True)

    # Configurar archivo de ASINs
    if args.asins_file:
        Config.ASINS_FILE = Path(args.asins_file)

    # Setup directories
    Config.setup_directories()

    # Health checks (a menos que se salte)
    if not args.skip_health_check:
        health_ok = HealthChecker.run_all_checks()
        if not health_ok:
            response = input("\n‚ö†Ô∏è  Algunos health checks fallaron. ¬øContinuar de todas formas? (y/N): ")
            if response.lower() != "y":
                print("‚ùå Pipeline abortado")
                sys.exit(1)

    # Crear pipeline
    pipeline = Pipeline(Config)

    # Cargar ASINs
    if args.asin:
        # Procesar solo un ASIN espec√≠fico
        asins = [args.asin.upper()]
        print(f"üéØ Modo single ASIN: {args.asin}")
    else:
        asins = pipeline.load_asins()

    if not asins:
        print("‚ùå No hay ASINs para procesar")
        sys.exit(1)

    # Ejecutar pipeline
    try:
        results = pipeline.run(asins)

        # Exit code basado en resultados
        if len(results["failed"]) == 0:
            sys.exit(0)
        elif len(results["success"]) > 0:
            sys.exit(2)  # Parcialmente exitoso
        else:
            sys.exit(1)  # Todos fallaron

    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Pipeline interrumpido por el usuario")
        sys.exit(130)
    except Exception as e:
        print(f"\n\n‚ùå Error fatal en el pipeline: {e}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
